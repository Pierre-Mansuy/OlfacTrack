{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7d6780-1114-4c64-b501-595600a43ade",
   "metadata": {},
   "source": [
    "# Olfactrack: 2D Tracking Pipeline for Olfactometer Videos\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Python pipeline enables 2D tracking of bumblebees in olfactometer videos. The notebook processes videos through five sequential stages, each handling a specific part of the workflow.\n",
    "\n",
    "### Workflow Stages\n",
    "\n",
    "1. **Import & Setup**: Import required libraries and configure the environment\n",
    "2. **ROI Selection**: Define the Y-tube structure by selecting four key points\n",
    "3. **Tracking**: Track bumblebee movement through the Y-tube apparatus\n",
    "4. **Visualization**: Generate plots and animations of tracking results\n",
    "5. **Analysis**: Calculate behavioral metrics and generate statistics\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "1. Ensure all required libraries are installed (see dependencies below)\n",
    "2. Configure the parameters at the beginning of each section\n",
    "3. Run the cells in order from top to bottom\n",
    "4. When prompted, mark the Y-tube structure by clicking on four points in each video frame\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "This notebook requires the following libraries:\n",
    "- OpenCV (`opencv-python`)\n",
    "- NumPy\n",
    "- Pandas\n",
    "- Matplotlib\n",
    "- Seaborn\n",
    "\n",
    "You can install them with: \n",
    "\n",
    "pip install opencv-python numpy pandas matplotlib seaborn jupyter\n",
    "\n",
    "### Outputs\n",
    "\n",
    "The notebook generates several files during processing:\n",
    "- `selected_points.csv`: Contains ROI coordinates for each video\n",
    "- `processed_<video_name>.csv`: Tracking data with X,Y coordinates and behavioral metrics\n",
    "- `results.csv`: Summary file with tracking metrics for all videos\n",
    "- Various visualization plots and animations when requested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bbcb8a-edc4-45bd-b61e-91406f22f483",
   "metadata": {},
   "source": [
    "## 1. Import & Setup\n",
    "\n",
    "This section imports all required libraries and configures the environment for the tracking pipeline. All functionality depends on these imports.\n",
    "\n",
    "### Required Libraries:\n",
    "- **OpenCV**: Video processing and computer vision\n",
    "- **NumPy & Pandas**: Data processing and analysis\n",
    "- **Matplotlib & Seaborn**: Data visualization\n",
    "- **Concurrent.futures**: Parallel processing of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c3dd1-10b8-41e3-a49f-c67c8467ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2                 # OpenCV for video processing and computer vision\n",
    "import os                  # Operating system utilities\n",
    "import pandas as pd        # Data analysis and manipulation\n",
    "import numpy as np         # Numerical computing\n",
    "import ast                 # Abstract Syntax Tree module for parsing\n",
    "import concurrent.futures  # Parallel processing\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time                # Time utilities\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import seaborn as sns      # Enhanced visualization\n",
    "import re                  # Regular expressions\n",
    "\n",
    "# Jupyter-specific settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.max_open_warning'] = 50  # Avoid warnings when displaying many figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2fb411-3106-4770-bc6b-0b684a44223b",
   "metadata": {},
   "source": [
    "## 2. ROI Selection\n",
    "\n",
    "This section allows you to select Regions of Interest (ROIs) by manually clicking on specific points in each video. For each olfactometer video, you will need to mark four key points that define the Y-tube structure:\n",
    "\n",
    "1. **Point 1**: Bottom entrance point (where the bumblebee enters the Y-tube)\n",
    "2. **Point 2**: Y-junction center point (where the tube branches)\n",
    "3. **Point 3**: Left arm endpoint (tip of the left branch)\n",
    "4. **Point 4**: Right arm endpoint (tip of the right branch)\n",
    "\n",
    "The notebook will show you the middle frame of each video and prompt you to click on these points. The coordinates are then saved to a CSV file for later use in the tracking phase.\n",
    "\n",
    "### Process Flow:\n",
    "1. Load each video file\n",
    "2. Display the middle frame\n",
    "3. User clicks to mark the 4 key points\n",
    "4. Coordinates are saved to CSV\n",
    "5. Process repeats for each video in the directory\n",
    "\n",
    "### When selecting points:\n",
    "- Click precisely on the key locations of the Y-tube\n",
    "- Points are numbered as you click them\n",
    "- Maintain consistent selection order across all videos\n",
    "- Press ESC to cancel the selection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a2059-f774-4647-841b-0571be70dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ROI SELECTION CONFIGURATION =====\n",
    "# These parameters control the region of interest selection process\n",
    "\n",
    "# File settings\n",
    "VIDEO_EXTENSIONS = ['.mp4']    # File extensions to process\n",
    "OUTPUT_CSV = 'selected_points.csv'  # Name of the output CSV file\n",
    "\n",
    "# UI settings\n",
    "MARKER_SIZE = 5                # Size of the marker circle when selecting points\n",
    "MARKER_COLOR = (0, 255, 0)     # Color of the marker (BGR format)\n",
    "TEXT_COLOR = (0, 0, 255)       # Color of the text labels (BGR format)\n",
    "FONT_SIZE = 0.7                # Size of the text labels\n",
    "FONT_THICKNESS = 2             # Thickness of the text labels\n",
    "WINDOW_NAME = \"Select 4 points (click to mark)\"  # Window title\n",
    "# =======================================\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def select_points_from_videos(video_directory):\n",
    "    \"\"\"\n",
    "    Process all video files in a directory and allow users to select 4 points from each video's middle frame.\n",
    "    Points are saved to a CSV file in the same directory.\n",
    "    \n",
    "    Args:\n",
    "        video_directory (str): Path to the directory containing video files\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the generated CSV file\n",
    "    \"\"\"\n",
    "    # Path to save the CSV file in the same folder as videos\n",
    "    csv_file_path = os.path.join(video_directory, OUTPUT_CSV)\n",
    "    \n",
    "    # List to store data for the DataFrame\n",
    "    data_selected_points = []\n",
    "    \n",
    "    # List all files in the directory\n",
    "    video_files = [f for f in os.listdir(video_directory) if f.endswith('.mp4')]\n",
    "    print(f\"Found {len(video_files)} video files to process\")\n",
    "    \n",
    "    for video_file in video_files:\n",
    "        points = process_single_video(video_directory, video_file)\n",
    "        \n",
    "        if points and len(points) == 4:\n",
    "            # Store the points and video name in the data list\n",
    "            data_selected_points.append({\n",
    "                'Video File': video_file,\n",
    "                'Point 1 (x, y)': points[0],\n",
    "                'Point 2 (x, y)': points[1],\n",
    "                'Point 3 (x, y)': points[2],\n",
    "                'Point 4 (x, y)': points[3]\n",
    "            })\n",
    "            print(f\"Selected points for {video_file}: {points}\")\n",
    "    \n",
    "    # Create a DataFrame from the collected data\n",
    "    df_selected_points = pd.DataFrame(data_selected_points)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df_selected_points.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Process finished. All points have been saved to {csv_file_path}.\")\n",
    "    \n",
    "    return csv_file_path\n",
    "\n",
    "def process_single_video(video_directory, video_filename):\n",
    "    \"\"\"\n",
    "    Process a single video file to select 4 points from its middle frame.\n",
    "    \n",
    "    Args:\n",
    "        video_directory (str): Directory containing the video file\n",
    "        video_filename (str): Name of the video file to process\n",
    "    \n",
    "    Returns:\n",
    "        list: List of 4 (x, y) coordinate tuples if successful, empty list otherwise\n",
    "    \"\"\"\n",
    "    video_path = os.path.join(video_directory, video_filename)\n",
    "    print(f\"Processing video: {video_filename}\")\n",
    "    \n",
    "    # Initialize points list for this video\n",
    "    points = []\n",
    "    \n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video {video_filename}.\")\n",
    "        return []\n",
    "    \n",
    "    # Get total frames and compute the middle frame index\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    mid_frame_idx = total_frames // 2\n",
    "    \n",
    "    # Set the video position to the middle frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame_idx)\n",
    "    \n",
    "    # Read the middle frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Error: Could not read the middle frame of {video_filename}.\")\n",
    "        cap.release()\n",
    "        return []\n",
    "    \n",
    "    # Display the middle frame for point selection\n",
    "    cv2.imshow(WINDOW_NAME, frame)\n",
    "    \n",
    "    # Define the mouse callback function to capture points\n",
    "    def click_event(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            # Append the clicked point (x, y) to the points list\n",
    "            points.append((x, y))\n",
    "            print(f\"Point {len(points)} selected: ({x}, {y})\")\n",
    "            \n",
    "            # Draw a small circle at the clicked point\n",
    "            cv2.circle(param, (x, y), MARKER_SIZE, MARKER_COLOR, -1)\n",
    "            # Add point number text\n",
    "            cv2.putText(param, str(len(points)), (x+10, y-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
    "            cv2.imshow(WINDOW_NAME, param)\n",
    "            \n",
    "            # Stop after 4 points\n",
    "            if len(points) == 4:\n",
    "                print(\"4 points selected. Continuing to next video.\")\n",
    "                cv2.destroyAllWindows()\n",
    "    \n",
    "    # Set the mouse callback function to capture points\n",
    "    cv2.setMouseCallback(WINDOW_NAME, click_event, param=frame)\n",
    "    \n",
    "    # Wait until 4 points are selected\n",
    "    while len(points) < 4 and cv2.getWindowProperty(WINDOW_NAME, cv2.WND_PROP_VISIBLE) >= 1:\n",
    "        key = cv2.waitKey(100)\n",
    "        # Allow user to exit with ESC key\n",
    "        if key == 27:  # ESC key\n",
    "            print(\"Selection canceled by user\")\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92929d-57cf-4287-aef2-8a2a20764a9e",
   "metadata": {},
   "source": [
    "### ROI Selection Execution\n",
    "\n",
    "Execute the ROI selection process for all videos in the specified directory. The results will be saved to `selected_points.csv`.\n",
    "\n",
    "**Instructions:**\n",
    "1. Set the video directory path in the cell below\n",
    "2. Run the cell to start the ROI selection process\n",
    "3. For each video, click on the 4 key points in the following order:\n",
    "   - Point 1: Bottom entrance point\n",
    "   - Point 2: Y-junction center point\n",
    "   - Point 3: Left arm endpoint\n",
    "   - Point 4: Right arm endpoint\n",
    "4. Press ESC to cancel the selection for the current video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebc4d0-7c73-49af-b6df-7f9616cd73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ROI SELECTION EXECUTION =====\n",
    "# Set the directory path containing your olfactometer videos\n",
    "VIDEO_DIRECTORY = r'C:\\Users\\YourUsername\\Videos'  # Change this path to your video folder\n",
    "# ==================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the directory containing the video files\n",
    "    video_dir = VIDEO_DIRECTORY\n",
    "    \n",
    "    # Uncomment the block below to use a directory selection dialog instead of hardcoded path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import tkinter as tk\n",
    "        from tkinter import filedialog\n",
    "        \n",
    "        # Create and hide the Tkinter root window\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        \n",
    "        # Show directory selection dialog\n",
    "        selected_dir = filedialog.askdirectory(title=\"Select directory containing videos\")\n",
    "        \n",
    "        # Use the selected directory if one was chosen\n",
    "        if selected_dir:\n",
    "            video_dir = selected_dir\n",
    "            print(f\"Using selected directory: {video_dir}\")\n",
    "    except ImportError:\n",
    "        print(\"Tkinter not available - using configured directory path\")\n",
    "    \n",
    "    \"\"\"\n",
    "    if os.path.isdir(video_dir):\n",
    "        select_points_from_videos(video_dir)\n",
    "    else:\n",
    "        print(f\"Error: Directory '{video_dir}' not found or not accessible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe94aa-e624-4f25-a318-22b1d0546de1",
   "metadata": {},
   "source": [
    "## 3. Tracking\n",
    "\n",
    "This section implements the core tracking functionality to detect and follow bumblebees as they move through the Y-tube. The tracking algorithm uses computer vision techniques including background subtraction, contour detection, and trajectory analysis.\n",
    "\n",
    "### Tracking Process:\n",
    "\n",
    "1. **ROI Loading**: Read the Y-tube coordinates from the CSV file\n",
    "2. **Preprocessing**: \n",
    "   - Create masks for each Y-tube segment (bottom, left, right)\n",
    "   - Apply background subtraction to isolate moving objects\n",
    "   - Use morphological operations to clean up the image\n",
    "3. **Detection**:\n",
    "   - Find contours in the binary mask\n",
    "   - Filter contours based on area and quantity\n",
    "   - Compute centroid of detected bumblebee\n",
    "4. **Tracking**:\n",
    "   - Record X,Y coordinates frame by frame\n",
    "   - Project points onto Y-tube segments\n",
    "   - Clean and interpolate trajectory data\n",
    "5. **Metrics Calculation**:\n",
    "   - Compute velocity and displacement\n",
    "   - Calculate segment proportions\n",
    "   - Generate additional behavioral metrics\n",
    "\n",
    "### Key Parameters:\n",
    "- Detection thresholds for size and movement\n",
    "- Background subtraction sensitivity\n",
    "- Trajectory cleaning parameters\n",
    "- Y-tube segment definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deaaf3d-cac2-4d97-8452-5b2339589635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TRACKING CONFIGURATION =====\n",
    "# These parameters control the bumblebee detection and tracking process\n",
    "\n",
    "# Background subtraction parameters\n",
    "HISTORY = 500                      # History length for background subtractor\n",
    "VAR_THRESHOLD = 200                # Threshold for background subtractor\n",
    "DETECT_SHADOWS = True              # Whether to detect shadows\n",
    "BLUR_SIZE = 5                      # Size of median blur kernel\n",
    "\n",
    "# Detection parameters\n",
    "MAX_CONTOURS = 2                   # Maximum number of contours allowed\n",
    "MIN_AREA = 30                      # Minimum contour area (pixels²)\n",
    "MAX_AREA = 3000                    # Maximum contour area (pixels²)\n",
    "MAX_DISTANCE = 200                 # Maximum distance between multiple contours\n",
    "\n",
    "# Y-tube structure parameters\n",
    "TUBE_THICKNESS = 60                # Y-tube thickness for mask creation\n",
    "\n",
    "# Trajectory cleaning parameters\n",
    "CLEAN_WINDOW_SIZE = 50             # Window size for cleaning coordinates\n",
    "CLEAN_MIN_VALID = 10               # Minimum valid points in window\n",
    "CLEAN_DISTANCE_THRESHOLD = 30      # Maximum allowed displacement between frames\n",
    "MAX_ITERATIONS = 5                 # Maximum iterations for trajectory denoising\n",
    "# ===================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "def extract_coordinates(row):\n",
    "    \"\"\"\n",
    "    Extract and convert coordinates from a DataFrame row to tuples.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.DataFrame): DataFrame row containing the coordinate points.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Four coordinate tuples (point_1, point_2, point_3, point_4) or (None, None, None, None) if error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        point_1 = ast.literal_eval(row['Point 1 (x, y)'].values[0])\n",
    "        point_2 = ast.literal_eval(row['Point 2 (x, y)'].values[0])\n",
    "        point_3 = ast.literal_eval(row['Point 3 (x, y)'].values[0])\n",
    "        point_4 = ast.literal_eval(row['Point 4 (x, y)'].values[0])\n",
    "        return point_1, point_2, point_3, point_4\n",
    "    except (ValueError, KeyError, IndexError) as e:\n",
    "        print(f\"Error parsing coordinates: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def clip_point(point, frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Clip a point to ensure it lies within the frame boundaries.\n",
    "    \n",
    "    Args:\n",
    "        point (tuple): (x, y) coordinates of the point.\n",
    "        frame_width (int): Width of the frame.\n",
    "        frame_height (int): Height of the frame.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Clipped (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    x, y = point\n",
    "    x = max(0, min(frame_width - 1, x))\n",
    "    y = max(0, min(frame_height - 1, y))\n",
    "    return x, y\n",
    "\n",
    "def create_thick_segment(center, end, thickness, frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Create a thick segment as a polygon around a line segment.\n",
    "    \n",
    "    Args:\n",
    "        center (tuple): (x, y) coordinates of the segment's center point.\n",
    "        end (tuple): (x, y) coordinates of the segment's end point.\n",
    "        thickness (int): Thickness of the segment in pixels.\n",
    "        frame_width (int): Width of the frame.\n",
    "        frame_height (int): Height of the frame.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Array of polygon points defining the thick segment.\n",
    "    \"\"\"\n",
    "    dx, dy = end[0] - center[0], end[1] - center[1]\n",
    "    \n",
    "    # Handle the case where center and end are the same point\n",
    "    if dx == 0 and dy == 0:\n",
    "        return np.array([center, center, center, center], dtype=np.int32)\n",
    "        \n",
    "    length = np.sqrt(dx**2 + dy**2)\n",
    "    dx, dy = dx / length, dy / length\n",
    "    perp_x, perp_y = -dy, dx\n",
    "    \n",
    "    # Create four corners of the polygon\n",
    "    p1 = clip_point((int(center[0] + perp_x * thickness), int(center[1] + perp_y * thickness)), frame_width, frame_height)\n",
    "    p2 = clip_point((int(center[0] - perp_x * thickness), int(center[1] - perp_y * thickness)), frame_width, frame_height)\n",
    "    p3 = clip_point((int(end[0] - perp_x * thickness), int(end[1] - perp_y * thickness)), frame_width, frame_height)\n",
    "    p4 = clip_point((int(end[0] + perp_x * thickness), int(end[1] + perp_y * thickness)), frame_width, frame_height)\n",
    "    \n",
    "    return np.array([p1, p2, p3, p4], dtype=np.int32)\n",
    "\n",
    "def clean_coordinates(coord_list, window_size=CLEAN_WINDOW_SIZE, min_valid=CLEAN_MIN_VALID):\n",
    "    \"\"\"\n",
    "    Cleans the coordinates by removing isolated valid points surrounded by mostly None values.\n",
    "    \n",
    "    Args:\n",
    "        coord_list (list): A list of coordinates [[frame, x, y], ...].\n",
    "        window_size (int): Size of the window to check for density.\n",
    "        min_valid (int): Minimum number of non-None points required to keep data.\n",
    "        \n",
    "    Returns:\n",
    "        list: The cleaned list of coordinates.\n",
    "    \"\"\"\n",
    "    half_window = window_size // 2\n",
    "    coord_list = coord_list.copy()  # Make a copy to avoid modifying the original list\n",
    "    \n",
    "    for frame in range(half_window, len(coord_list) - half_window):\n",
    "        # Extract the window around the current frame\n",
    "        window = coord_list[frame - half_window:frame + half_window + 1]\n",
    "        \n",
    "        # Count valid (non-None) data points in the window\n",
    "        valid_count = sum(1 for entry in window if entry[1] is not None and entry[2] is not None)\n",
    "        \n",
    "        # If valid data points are less than the threshold, discard them\n",
    "        if valid_count < min_valid:\n",
    "            coord_list[frame][1] = None\n",
    "            coord_list[frame][2] = None\n",
    "    \n",
    "    return coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ebdf9-c927-4227-8746-763f52c86136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_segment_distance(px, py, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculate the distance from a point to a line segment and the projection onto that segment.\n",
    "    \n",
    "    Args:\n",
    "        px (float): x-coordinate of the point.\n",
    "        py (float): y-coordinate of the point.\n",
    "        x1 (float): x-coordinate of the segment's start.\n",
    "        y1 (float): y-coordinate of the segment's start.\n",
    "        x2 (float): x-coordinate of the segment's end.\n",
    "        y2 (float): y-coordinate of the segment's end.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (distance, proportion, (proj_x, proj_y)) where:\n",
    "            - distance is the perpendicular distance to the segment\n",
    "            - proportion is the position along the segment (0 at start, 1 at end)\n",
    "            - (proj_x, proj_y) are the coordinates of the projection point\n",
    "    \"\"\"\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    \n",
    "    # Handle degenerate case where segment is a point\n",
    "    if dx == 0 and dy == 0:\n",
    "        return np.sqrt((px - x1)**2 + (py - y1)**2), 0, (x1, y1)\n",
    "    \n",
    "    dot = (px - x1) * dx + (py - y1) * dy\n",
    "    length_sq = dx * dx + dy * dy\n",
    "    proportion = dot / length_sq if length_sq != 0 else 0\n",
    "    proportion = max(0, min(1, proportion))  # Clamp to [0,1]\n",
    "    \n",
    "    # Calculate projection point\n",
    "    proj_x = x1 + proportion * dx\n",
    "    proj_y = y1 + proportion * dy\n",
    "    \n",
    "    # Calculate distance\n",
    "    distance = np.sqrt((px - proj_x)**2 + (py - proj_y)**2)\n",
    "    \n",
    "    return distance, proportion, (proj_x, proj_y)\n",
    "\n",
    "def find_closest_segment_with_projection(row, px_col, py_col, segments):\n",
    "    \"\"\"\n",
    "    Find the closest segment to a given point and calculate projection details.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row of the DataFrame.\n",
    "        px_col (str): Column name for x-coordinates.\n",
    "        py_col (str): Column name for y-coordinates.\n",
    "        segments (list): List of segments as ((x1, y1), (x2, y2), segment_id).\n",
    "        \n",
    "    Returns:\n",
    "        tuple: ((distance, proportion, (proj_x, proj_y)), segment_id) of the closest segment.\n",
    "    \"\"\"\n",
    "    # Skip calculation if coordinates are None/NaN\n",
    "    if pd.isna(row[px_col]) or pd.isna(row[py_col]):\n",
    "        # Return a default value with NaNs\n",
    "        return ((np.nan, np.nan, (np.nan, np.nan)), \"\")\n",
    "    \n",
    "    px, py = row[px_col], row[py_col]\n",
    "    \n",
    "    # Calculate distances and projections for all segments\n",
    "    distances_and_projections = [\n",
    "        (point_to_segment_distance(px, py, x1, y1, x2, y2), seg_id)\n",
    "        for (x1, y1), (x2, y2), seg_id in segments\n",
    "    ]\n",
    "    \n",
    "    # Return the entry with minimum distance\n",
    "    return min(distances_and_projections, key=lambda x: x[0][0])\n",
    "\n",
    "def denoise_trajectory(df, distance_threshold, max_iterations=MAX_ITERATIONS):\n",
    "    \"\"\"\n",
    "    Denoise a trajectory by removing and interpolating points with abnormal instantaneous displacement.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing trajectory data.\n",
    "        distance_threshold (float): Maximum allowed instantaneous displacement.\n",
    "        max_iterations (int): Maximum number of denoising iterations.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Denoised DataFrame.\n",
    "    \"\"\"\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        # Calculate instantaneous distances\n",
    "        df[\"Instantaneous_Distance\"] = np.sqrt(\n",
    "            np.diff(df[\"X_raw_projected\"], prepend=np.nan) ** 2 +\n",
    "            np.diff(df[\"Y_raw_projected\"], prepend=np.nan) ** 2\n",
    "        )\n",
    "\n",
    "        # Identify points to remove (distance > threshold)\n",
    "        outlier_indices = df[df[\"Instantaneous_Distance\"] > distance_threshold].index\n",
    "\n",
    "        # If no outliers, break the loop\n",
    "        if outlier_indices.empty:\n",
    "            break\n",
    "\n",
    "        # Include surrounding points for removal (window of 5 points centered on outlier)\n",
    "        indices_to_remove = set()\n",
    "        for idx in outlier_indices:\n",
    "            for offset in range(-2, 3):  # -2, -1, 0, 1, 2\n",
    "                if 0 <= idx + offset < len(df):\n",
    "                    indices_to_remove.add(idx + offset)\n",
    "\n",
    "        # Remove the points by setting them to NaN\n",
    "        df.loc[sorted(indices_to_remove), [\"X_raw_projected\", \"Y_raw_projected\"]] = np.nan\n",
    "\n",
    "        # Interpolate missing values\n",
    "        df[\"X_raw_projected\"] = df[\"X_raw_projected\"].interpolate(method=\"linear\")\n",
    "        df[\"Y_raw_projected\"] = df[\"Y_raw_projected\"].interpolate(method=\"linear\")\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    # Recalculate instantaneous distances after final cleanup\n",
    "    df[\"Instantaneous_Distance\"] = np.sqrt(\n",
    "        np.diff(df[\"X_raw_projected\"], prepend=np.nan) ** 2 +\n",
    "        np.diff(df[\"Y_raw_projected\"], prepend=np.nan) ** 2\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9fe2e-75c2-442b-ac43-2d922f0276a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(file_name, folder_path, df):\n",
    "    \"\"\"\n",
    "    Process a video file to detect bumblebees and calculate their trajectories in the Y-tube.\n",
    "    This function performs the following steps:\n",
    "    1. Extracts Y-tube coordinates from metadata\n",
    "    2. Creates a mask for the Y-tube branches\n",
    "    3. Applies background subtraction to isolate moving objects\n",
    "    4. Detects contours and filters them based on size and number\n",
    "    5. Tracks the position of the bumblebee through the Y-tube\n",
    "    \n",
    "    Args:\n",
    "        file_name (str): Name of the video file.\n",
    "        folder_path (str): Path to the folder containing the video.\n",
    "        df (pd.DataFrame): DataFrame containing point metadata and coordinates.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame with tracking results, list of segments)\n",
    "    \"\"\"\n",
    "    # Filter the row for the current video\n",
    "    row = df[df['Video File'] == file_name]\n",
    "    if row.empty:\n",
    "        print(f\"No data found for {file_name}.\")\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    # Extract coordinates that define the Y-tube structure\n",
    "    point_1, point_2, point_3, point_4 = extract_coordinates(row)\n",
    "    if None in (point_1, point_2, point_3, point_4):\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    x1, y1 = point_1  # Bottom point\n",
    "    x2, y2 = point_2  # Center point\n",
    "    x3, y3 = point_3  # Left point\n",
    "    x4, y4 = point_4  # Right point\n",
    "\n",
    "    # Define the three segments of interest (center-to-point, segment label)\n",
    "    segments = [\n",
    "        ((x2, y2), (x1, y1), \"bottom\"),\n",
    "        ((x2, y2), (x3, y3), \"left\"),\n",
    "        ((x2, y2), (x4, y4), \"right\")\n",
    "    ]\n",
    "    \n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(os.path.join(folder_path, file_name))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Video file {file_name} could not be opened.\")\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    # Initialize background subtractor\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(history=HISTORY, varThreshold=VAR_THRESHOLD, detectShadows=DETECT_SHADOWS)\n",
    "    coordinates = []\n",
    "\n",
    "    # Read first frame to get dimensions\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read the first frame.\")\n",
    "        cap.release()\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # Create mask for the Y-tube structure\n",
    "    mask = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
    "    for center, end, segment_id in segments:\n",
    "        poly = create_thick_segment(center, end, thickness=TUBE_THICKNESS, frame_width=frame_width, frame_height=frame_height)\n",
    "        cv2.fillPoly(mask, [poly], 255)\n",
    "\n",
    "    # Reset to beginning of video\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    # Process each frame\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        fgmask = cv2.medianBlur(fgmask, BLUR_SIZE)\n",
    "\n",
    "        # Apply morphological operations to clean up the mask\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Apply the Y-tube mask to focus only on our region of interest\n",
    "        fgmask = cv2.bitwise_and(fgmask, mask)\n",
    "        \n",
    "        # Apply median blur again to smooth the result\n",
    "        fgmask = cv2.medianBlur(fgmask, BLUR_SIZE)\n",
    "\n",
    "        # Threshold to create binary mask\n",
    "        _, binary_mask = cv2.threshold(fgmask, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours in the binary mask\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Filter 1: Based on number of contours\n",
    "        if len(contours) > MAX_CONTOURS:\n",
    "            coordinates.append([frame_number, None, None])\n",
    "            continue\n",
    "\n",
    "        # Filter 2: Based on contour area\n",
    "        if contours:\n",
    "            largest_contour_area = max(cv2.contourArea(c) for c in contours)\n",
    "            if largest_contour_area > MAX_AREA or largest_contour_area < MIN_AREA:\n",
    "                coordinates.append([frame_number, None, None])\n",
    "                continue\n",
    "\n",
    "        # Filter 3: Based on distance between contour centroids\n",
    "        contour_centroids = []\n",
    "        for contour in contours:\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                contour_centroids.append((cX, cY))\n",
    "\n",
    "        # Check if multiple centroids are too far apart\n",
    "        too_far_apart = False\n",
    "        for i, (x1, y1) in enumerate(contour_centroids):\n",
    "            for j, (x2, y2) in enumerate(contour_centroids):\n",
    "                if i != j:\n",
    "                    dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "                    if dist > MAX_DISTANCE:\n",
    "                        too_far_apart = True\n",
    "                        break\n",
    "            if too_far_apart:\n",
    "                break\n",
    "\n",
    "        if too_far_apart:\n",
    "            coordinates.append([frame_number, None, None])\n",
    "            continue\n",
    "\n",
    "        # If all filters pass, use the largest contour centroid\n",
    "        black_point = None\n",
    "        if contours:\n",
    "            sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "            largest_contour = sorted_contours[0]\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                black_point = (cX, cY)\n",
    "\n",
    "        # Record coordinates (or None if no valid point found)\n",
    "        coordinates.append([frame_number, None if black_point is None else black_point[0], \n",
    "                           None if black_point is None else black_point[1]])\n",
    "\n",
    "    # Release video resources\n",
    "    cap.release()\n",
    "\n",
    "    # Clean coordinates to remove isolated detections\n",
    "    cleaned_coordinates = clean_coordinates(coordinates)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(cleaned_coordinates, columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed01d9-36c3-4a64-b58b-1049afc3cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_background_subtraction(file_name, folder_path, df):\n",
    "    \"\"\"\n",
    "    Visualize the background subtraction and object detection process in real-time.\n",
    "    Shows the binary mask resulting from background subtraction and morphological operations.\n",
    "    This helps in understanding how well the object (bumblebee) is being detected.\n",
    "    \n",
    "    Args:\n",
    "        file_name (str): Name of the video file.\n",
    "        folder_path (str): Path to the folder containing the video.\n",
    "        df (pd.DataFrame): DataFrame containing point metadata.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Empty DataFrame and segments list (just for consistency with process_video).\n",
    "    \"\"\"\n",
    "    # Filter the row for the current video\n",
    "    row = df[df['Video File'] == file_name]\n",
    "    if row.empty:\n",
    "        print(f\"No data found for {file_name}.\")\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    # Extract coordinates\n",
    "    point_1, point_2, point_3, point_4 = extract_coordinates(row)\n",
    "    if None in (point_1, point_2, point_3, point_4):\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    # Define segments\n",
    "    x1, y1 = point_1\n",
    "    x2, y2 = point_2\n",
    "    x3, y3 = point_3\n",
    "    x4, y4 = point_4\n",
    "\n",
    "    segments = [\n",
    "        ((x2, y2), (x1, y1), \"bottom\"),\n",
    "        ((x2, y2), (x3, y3), \"left\"),\n",
    "        ((x2, y2), (x4, y4), \"right\")\n",
    "    ]\n",
    "    \n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(os.path.join(folder_path, file_name))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Video file {file_name} could not be opened.\")\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    # Initialize background subtractor\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(history=300, varThreshold=200, detectShadows=True)\n",
    "\n",
    "    # Read first frame to get dimensions\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read the first frame.\")\n",
    "        cap.release()\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # Create mask for the Y-tube\n",
    "    mask = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
    "    for center, end, segment_id in segments:\n",
    "        poly = create_thick_segment(center, end, thickness=TUBE_THICKNESS, frame_width=frame_width, frame_height=frame_height)\n",
    "        cv2.fillPoly(mask, [poly], 255)\n",
    "\n",
    "    # Reset to beginning of video\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    # Process each frame\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        fgmask = cv2.medianBlur(fgmask, 5)\n",
    "\n",
    "        # Apply morphological operations\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Apply the mask\n",
    "        masked_fgmask = cv2.bitwise_and(fgmask, mask)\n",
    "        masked_fgmask = cv2.medianBlur(masked_fgmask, 5)\n",
    "\n",
    "        # Create binary mask for visualization\n",
    "        _, binary_mask = cv2.threshold(masked_fgmask, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Display the binary mask\n",
    "        cv2.imshow('Background Subtraction Result', binary_mask)\n",
    "        \n",
    "        # Wait for 'q' key to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be7d4c-e071-420a-9820-48ef9f582e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_contour_detection(file_name, folder_path, df):\n",
    "    \"\"\"\n",
    "    Visualize the contour detection process in real-time, showing detected objects.\n",
    "    Draws the detected bumblebee contours, their centroids, and the Y-tube segments.\n",
    "    This helps in debugging the tracking process and assessing the quality of contour detection.\n",
    "    \n",
    "    Args:\n",
    "        file_name (str): Name of the video file.\n",
    "        folder_path (str): Path to the folder containing the video.\n",
    "        df (pd.DataFrame): DataFrame containing point metadata.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Empty DataFrame and segments list (for consistency with process_video).\n",
    "    \"\"\"\n",
    "    # Filter the row for the current video\n",
    "    row = df[df['Video File'] == file_name]\n",
    "    if row.empty:\n",
    "        print(f\"No data found for {file_name}.\")\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    # Extract coordinates\n",
    "    point_1, point_2, point_3, point_4 = extract_coordinates(row)\n",
    "    if None in (point_1, point_2, point_3, point_4):\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    # Define segments\n",
    "    x1, y1 = point_1\n",
    "    x2, y2 = point_2\n",
    "    x3, y3 = point_3\n",
    "    x4, y4 = point_4\n",
    "\n",
    "    segments = [\n",
    "        ((x2, y2), (x1, y1), \"bottom\"),\n",
    "        ((x2, y2), (x3, y3), \"left\"),\n",
    "        ((x2, y2), (x4, y4), \"right\")\n",
    "    ]\n",
    "    \n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(os.path.join(folder_path, file_name))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Video file {file_name} could not be opened.\")\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    # Initialize background subtractor\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(history=300, varThreshold=200, detectShadows=True)\n",
    "\n",
    "    # Read first frame to get dimensions\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read the first frame.\")\n",
    "        cap.release()\n",
    "        return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []\n",
    "\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # Create mask for the Y-tube\n",
    "    mask = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
    "    for center, end, segment_id in segments:\n",
    "        poly = create_thick_segment(center, end, thickness=TUBE_THICKNESS, frame_width=frame_width, frame_height=frame_height)\n",
    "        cv2.fillPoly(mask, [poly], 255)\n",
    "\n",
    "    # Reset to beginning of video\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    # Process each frame\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        fgmask = cv2.medianBlur(fgmask, 5)\n",
    "\n",
    "        # Apply morphological operations\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Apply the mask\n",
    "        masked_fgmask = cv2.bitwise_and(fgmask, mask)\n",
    "        masked_fgmask = cv2.medianBlur(masked_fgmask, 5)\n",
    "\n",
    "        # Create binary mask\n",
    "        _, binary_mask = cv2.threshold(masked_fgmask, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours in the binary mask\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a visualization frame\n",
    "        vis_frame = frame.copy()\n",
    "        \n",
    "        # Draw Y-tube segments\n",
    "        for center, end, segment_id in segments:\n",
    "            cv2.line(vis_frame, center, end, (0, 255, 0), 2)\n",
    "            cv2.putText(vis_frame, segment_id, end, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # Draw detected contours with random colors\n",
    "        for contour in contours:\n",
    "            # Filter out tiny contours\n",
    "            if cv2.contourArea(contour) > MIN_AREA:\n",
    "                # Random color in BGR format\n",
    "                color = (np.random.randint(0, 256), np.random.randint(0, 256), np.random.randint(0, 256))\n",
    "                \n",
    "                # Draw contour\n",
    "                cv2.drawContours(vis_frame, [contour], -1, color, 2)\n",
    "                \n",
    "                # Draw centroid\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    cv2.circle(vis_frame, (cX, cY), 5, color, -1)\n",
    "                    cv2.putText(vis_frame, f\"Area: {cv2.contourArea(contour):.1f}\", (cX + 10, cY), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Contour Detection', vis_frame)\n",
    "\n",
    "        # Wait for 'q' key to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return pd.DataFrame(columns=[\"Frame\", \"X_raw\", \"Y_raw\"]), []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf550eb1-cd35-42b8-b1b8-d53e7fb83123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_video_parallel(file_name, folder_path, df_segments):\n",
    "    \"\"\"\n",
    "    Process a video file with complete tracking workflow including interpolation and trajectory analysis.\n",
    "    \n",
    "    Args:\n",
    "        file_name (str): Name of the video file.\n",
    "        folder_path (str): Path to the folder containing the video.\n",
    "        df_segments (pd.DataFrame): DataFrame containing point metadata.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (file_name, output_path) or None if processing failed.\n",
    "    \"\"\"\n",
    "    video_path = os.path.join(folder_path, file_name)\n",
    "    print(f\"Processing {file_name} in process {os.getpid()}\")\n",
    "\n",
    "    # Validate file existence and permissions\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: File not found - {video_path}\")\n",
    "        return None\n",
    "        \n",
    "    if not os.access(video_path, os.R_OK):\n",
    "        print(f\"Error: No read permission for - {video_path}\")\n",
    "        return None\n",
    "\n",
    "    # Try opening the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: Could not open video file - {video_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Successfully opened video: {file_name}\")\n",
    "    video.release()  # Release video here, it will be reopened in process_video\n",
    "    \n",
    "    # ========== TRACKING PHASE ==========\n",
    "    # Call tracking function\n",
    "    df, segments = process_video(file_name, folder_path, df_segments)\n",
    "    print(f\"Basic tracking completed for {file_name}\")\n",
    "    \n",
    "    # Check if tracking produced valid results\n",
    "    if df.empty or 'X_raw' not in df.columns:\n",
    "        print(f\"Error: Tracking failed for {file_name}\")\n",
    "        return None\n",
    "    \n",
    "    # ========== INTERPOLATION PHASE ==========\n",
    "    # Fill missing values using linear interpolation\n",
    "    df[\"X_raw_filled\"] = df[\"X_raw\"].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "    df[\"Y_raw_filled\"] = df[\"Y_raw\"].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "\n",
    "    # Check if interpolation succeeded\n",
    "    if df['X_raw_filled'].isna().any() or df['Y_raw_filled'].isna().any():\n",
    "        print(f\"Error: Interpolation failed for {file_name} - still have NaN values\")\n",
    "        return None\n",
    "\n",
    "    # ========== PROJECTION PHASE ==========\n",
    "    # Project points onto segments\n",
    "    df['intermediate'] = df.apply(find_closest_segment_with_projection, \n",
    "                                axis=1, \n",
    "                                args=('X_raw_filled', 'Y_raw_filled', segments))\n",
    "    \n",
    "    # Extract projection information\n",
    "    df['X_raw_projected'] = df['intermediate'].apply(lambda x: x[0][2][0])\n",
    "    df['Y_raw_projected'] = df['intermediate'].apply(lambda x: x[0][2][1])\n",
    "    \n",
    "    # Remove intermediate column to keep dataframe clean\n",
    "    df.drop(columns=['intermediate'], inplace=True)\n",
    "\n",
    "    # ========== DENOISING PHASE ==========\n",
    "    # Clean the trajectory by removing erratic movements\n",
    "    df = denoise_trajectory(df, distance_threshold=30, max_iterations=3)\n",
    "    \n",
    "    # Project points again after denoising for more accurate segment assignment\n",
    "    df['intermediate'] = df.apply(find_closest_segment_with_projection, \n",
    "                                axis=1, \n",
    "                                args=('X_raw_projected', 'Y_raw_projected', segments))\n",
    "    \n",
    "    # Extract final projection information\n",
    "    df['X_projected'] = df['intermediate'].apply(lambda x: x[0][2][0])\n",
    "    df['Y_projected'] = df['intermediate'].apply(lambda x: x[0][2][1])\n",
    "    df['proportion'] = df['intermediate'].apply(lambda x: x[0][1])\n",
    "    df['closest_segment'] = df['intermediate'].apply(lambda x: x[1])\n",
    "\n",
    "    # Remove intermediate column\n",
    "    df.drop(columns=['intermediate'], inplace=True)\n",
    "    \n",
    "    # ========== METRICS CALCULATION PHASE ==========\n",
    "    # Compute displacement metrics\n",
    "    df[\"delta_X\"] = df[\"X_projected\"].diff()\n",
    "    df[\"delta_Y\"] = df[\"Y_projected\"].diff()\n",
    "    \n",
    "    # Compute velocity (spatial and proportional)\n",
    "    df[\"velocity\"] = np.sqrt(df[\"delta_X\"]**2 + df[\"delta_Y\"]**2)\n",
    "    df[\"velocity_prop\"] = np.sqrt(df[\"proportion\"].diff()**2)\n",
    "    \n",
    "    # Compute cumulative distance\n",
    "    df[\"cumulative_distance\"] = df[\"velocity\"].cumsum()\n",
    "\n",
    "    # ========== OUTPUT PHASE ==========\n",
    "    # Save processed DataFrame to CSV\n",
    "    output_path = os.path.join(folder_path, f\"processed_{file_name}.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Processed trajectory data saved to {output_path}\")\n",
    "\n",
    "    return file_name, output_path  # Return processing result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905eed8a-fa32-4a6c-bc00-45069e81c05e",
   "metadata": {},
   "source": [
    "### Tracking Execution\n",
    "\n",
    "This cell executes the tracking process for all videos. The process runs in parallel threads to speed up execution. You can also visualize the background subtraction and contour detection in real-time to debug tracking issues.\n",
    "\n",
    "**Process Steps:**\n",
    "1. Load the CSV file with ROI coordinates\n",
    "2. Find all video files in the specified folder\n",
    "3. Optionally run visualization for the first video\n",
    "4. Process all videos in parallel threads\n",
    "5. Save trajectory data to CSV files\n",
    "\n",
    "**Output Files:**\n",
    "- `processed_<video_name>.csv`: CSV file containing tracking data for each video\n",
    "\n",
    "**Visualization Options:**\n",
    "- Set `VISUALIZE_BACKGROUND` to True to see background subtraction results\n",
    "- Set `VISUALIZE_CONTOURS` to True to see contour detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6a5af-29ea-4187-8467-0a7ca8ed88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TRACKING EXECUTION CONFIGURATION =====\n",
    "# Modify these parameters to configure the tracking execution\n",
    "\n",
    "# Directory settings\n",
    "FOLDER_PATH = r'C:\\Users\\YourUsername\\Videos'  # Path to video directory\n",
    "CSV_POINTS_FILE = 'selected_points.csv'                                # Filename of points data\n",
    "\n",
    "# Processing settings\n",
    "MAX_WORKERS = 8                                                        # Number of parallel processes\n",
    "\n",
    "# Visualization options\n",
    "VISUALIZE_BACKGROUND = False                                           # Set to True to visualize background subtraction\n",
    "VISUALIZE_CONTOURS = True                                              # Set to True to visualize contour detection\n",
    "# ==========================================\n",
    "\n",
    "# Main processing cell for bumblebee tracking in olfactometer videos\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Get a list of all .mp4 filenames in the folder\n",
    "mp4_files = [f for f in os.listdir(FOLDER_PATH) if f.endswith('.mp4')]\n",
    "print(f\"Found {len(mp4_files)} video files to process\")\n",
    "\n",
    "# Load the selected_points.csv file containing Y-tube coordinates\n",
    "csv_path = os.path.join(FOLDER_PATH, CSV_POINTS_FILE)\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"Cannot find coordinate file: {csv_path}\")\n",
    "\n",
    "df_segments = pd.read_csv(csv_path)\n",
    "print(f\"Loaded coordinate data for {len(df_segments)} videos\")\n",
    "\n",
    "# Initialize result containers\n",
    "df_results_list = []\n",
    "processed_trajectory_list = []\n",
    "\n",
    "# Define wrapper function for processing\n",
    "def process_video_wrapper(f):\n",
    "    return process_video_parallel(f, FOLDER_PATH, df_segments)\n",
    "\n",
    "# Optional: Run visualizations if configured\n",
    "if VISUALIZE_BACKGROUND or VISUALIZE_CONTOURS:\n",
    "    print(\"Running visualizations for the first video...\")\n",
    "    first_video = mp4_files[0] if mp4_files else None\n",
    "    \n",
    "    if first_video:\n",
    "        if VISUALIZE_BACKGROUND:\n",
    "            print(f\"Visualizing background subtraction for {first_video}\")\n",
    "            visualize_background_subtraction(first_video, FOLDER_PATH, df_segments)\n",
    "            \n",
    "        if VISUALIZE_CONTOURS:\n",
    "            print(f\"Visualizing contour detection for {first_video}\")\n",
    "            visualize_contour_detection(first_video, FOLDER_PATH, df_segments)\n",
    "    else:\n",
    "        print(\"No videos found for visualization\")\n",
    "\n",
    "# Process videos in parallel\n",
    "print(f\"Starting parallel processing with {MAX_WORKERS} workers...\")\n",
    "start_time_para = time.time()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    results = list(executor.map(process_video_wrapper, mp4_files))\n",
    "    \n",
    "end_time_para = time.time()\n",
    "para_duration = end_time_para - start_time_para\n",
    "\n",
    "# Clean results (remove None values from failed processing)\n",
    "valid_results = [res for res in results if res is not None]\n",
    "\n",
    "# Results summary\n",
    "print(\"=\" * 50)\n",
    "print(\"PROCESSING COMPLETED\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total videos processed: {len(valid_results)}/{len(mp4_files)}\")\n",
    "print(f\"Parallel execution time: {para_duration:.2f} seconds\")\n",
    "print(f\"Average time per video: {para_duration / len(mp4_files):.2f} seconds\")\n",
    "\n",
    "# Check for failed videos\n",
    "if len(valid_results) < len(mp4_files):\n",
    "    failed_videos = [f for f, res in zip(mp4_files, results) if res is None]\n",
    "    print(\"\\nFailed videos:\")\n",
    "    for vid in failed_videos:\n",
    "        print(f\" - {vid}\")\n",
    "\n",
    "print(\"\\nProcessed video files can be found at:\")\n",
    "print(f\" {FOLDER_PATH}\\\\processed_*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e3cd7-5834-46e8-b8db-74f2c7487a76",
   "metadata": {},
   "source": [
    "## 4. Trajectory Visualization\n",
    "\n",
    "This section provides tools to visualize the tracking results in various formats. The visualizations help to understand bumblebee behavior and validate tracking quality.\n",
    "\n",
    "### Types of Visualizations:\n",
    "1. **Raw Trajectory Plots**: Show the spatial path with color-coded segments\n",
    "2. **Time-series Plots**: Display movement metrics over time\n",
    "3. **Heatmaps**: Visualize spatial density of bumblebee positions\n",
    "4. **Animations**: Create dynamic visualizations of movement\n",
    "\n",
    "### How to Use:\n",
    "- Load processed trajectories using `load_processed_trajectories()`\n",
    "- Generate individual plots with the specific plotting functions\n",
    "- Use `visualize_all_trajectories()` to process multiple videos\n",
    "- Set `save_plots=True` to save visualizations to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6325a3-6c8c-40b0-8425-233bd14315ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== VISUALIZATION CONFIGURATION =====\n",
    "# These parameters control the visualization options\n",
    "\n",
    "# Plot settings\n",
    "DEFAULT_FIGSIZE = (10, 8)          # Default figure size for plots\n",
    "HEATMAP_FIGSIZE = (14, 12)         # Figure size for heatmaps\n",
    "TIMELINE_FIGSIZE = (18, 6)         # Figure size for timeline plots\n",
    "DPI = 300                          # Resolution for saved figures\n",
    "\n",
    "# Heatmap settings\n",
    "HEATMAP_RESOLUTION = 50            # Resolution of the heatmap grid\n",
    "HEATMAP_SMOOTHING = 3.0            # Gaussian smoothing factor for heatmaps\n",
    "\n",
    "# Animation settings\n",
    "ANIMATION_FPS = 30                 # Frames per second for animations\n",
    "ANIMATION_DPI = 100                # DPI for animations\n",
    "\n",
    "# Color schemes\n",
    "SEGMENT_COLORS = {                 # Colors for Y-tube segments\n",
    "    'bottom': 'orange',\n",
    "    'left': 'green',\n",
    "    'right': 'purple'\n",
    "}\n",
    "# ======================================\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def count_peaks_by_segment(proportion_series, segments_series):\n",
    "    \"\"\"\n",
    "    Count peaks in proportion values, categorized by segment.\n",
    "    A peak is counted when proportion crosses a threshold in either direction.\n",
    "    \n",
    "    Args:\n",
    "        proportion_series (pd.Series): Series of proportion values\n",
    "        segments_series (pd.Series): Series of segment labels\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (count_left, count_right, time_list)\n",
    "            - count_left: Number of peaks in the left segment\n",
    "            - count_right: Number of peaks in the right segment\n",
    "            - time_list: Frame indices where peaks occur\n",
    "    \"\"\"\n",
    "    count_left = 0  # For negative peaks (left)\n",
    "    count_right = 0  # For positive peaks (right)\n",
    "    above_threshold_left = True  # To track when the proportion goes above 0.25 for negative peaks\n",
    "    below_threshold_right = True  # To track when the proportion goes below -0.25 for positive peaks\n",
    "    time_list = []\n",
    "    \n",
    "    for time, (proportion, segment) in enumerate(zip(proportion_series, segments_series)):\n",
    "        if segment == \"bottom\" or segment == \"no_choice\":        \n",
    "            above_threshold_left = True  \n",
    "            below_threshold_right = True\n",
    "            continue\n",
    "                \n",
    "        if segment == \"left\" or segment == \"right\":\n",
    "            # Reset thresholds when crossing the middle range\n",
    "            if proportion >= -0.25:\n",
    "                above_threshold_left = True  # Allows negative peaks after crossing 0.25\n",
    "            if proportion <= 0.25:\n",
    "                below_threshold_right = True  # Allows positive peaks after crossing -0.25\n",
    "        \n",
    "            # Count right peaks (positive) after going below -0.25\n",
    "            if proportion >= 0.75 and below_threshold_right:\n",
    "                count_right += 1\n",
    "                below_threshold_right = False  # Prevents double counting\n",
    "                time_list.append(time)\n",
    "        \n",
    "            # Count left peaks (negative) after going above 0.25\n",
    "            if proportion <= -0.75 and above_threshold_left:\n",
    "                count_left += 1\n",
    "                above_threshold_left = False  # Prevents double counting\n",
    "                time_list.append(time)\n",
    "    \n",
    "    return count_left, count_right, time_list\n",
    "\n",
    "def load_processed_trajectories(folder_path):\n",
    "    \"\"\"\n",
    "    Load all processed trajectory CSV files from a specified folder.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing processed CSV files\n",
    "        \n",
    "    Returns:\n",
    "        list: List of tuples (filename, dataframe) for each processed trajectory\n",
    "    \"\"\"\n",
    "    # Find all processed CSV files\n",
    "    tracking_csv_files = [file for file in os.listdir(folder_path) \n",
    "                         if file.endswith(\".csv\") and \"processed_\" in file]\n",
    "    print(f\"Found {len(tracking_csv_files)} processed trajectory files\")\n",
    "    \n",
    "    # Load each file into a DataFrame\n",
    "    processed_trajectory_list = []\n",
    "    for csv_filename in tracking_csv_files:\n",
    "        csv_path = os.path.join(folder_path, csv_filename)\n",
    "        try:\n",
    "            df_tracking = pd.read_csv(csv_path)\n",
    "            # Convert 'left' segment proportions to negative for better visualization\n",
    "            df_tracking.loc[df_tracking['closest_segment'] == 'left', 'proportion'] *= -1\n",
    "            processed_trajectory_list.append([csv_filename, df_tracking])\n",
    "            print(f\"Loaded: {csv_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {csv_filename}: {e}\")\n",
    "    \n",
    "    return processed_trajectory_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a828d34-7f33-4a06-b4e4-3eff2d852138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_trajectory(filename, df, show_plot=True):\n",
    "    \"\"\"\n",
    "    Plot the raw tracked coordinates colored by segment.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Name of the file being visualized\n",
    "        df (pd.DataFrame): DataFrame containing trajectory data\n",
    "        show_plot (bool): Whether to display the plot immediately\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=DEFAULT_FIGSIZE)\n",
    "    \n",
    "    # Create scatter plot with colors by segment\n",
    "    sns.scatterplot(data=df, x=\"X_raw\", y=\"Y_raw\", hue='closest_segment', \n",
    "                   palette=SEGMENT_COLORS, s=20, alpha=0.7, ax=ax)\n",
    "    \n",
    "    # Draw lines to connect points and show trajectory path\n",
    "    ax.plot(df[\"X_raw\"], df[\"Y_raw\"], color='gray', alpha=0.3, linewidth=0.5)\n",
    "    \n",
    "    # Add Y-tube structure from the first and last points in each segment\n",
    "    segments = ['bottom', 'left', 'right']\n",
    "    for segment in segments:\n",
    "        segment_df = df[df['closest_segment'] == segment]\n",
    "        if not segment_df.empty:\n",
    "            # Draw a thicker line for the segment\n",
    "            ax.plot(segment_df[\"X_raw\"], segment_df[\"Y_raw\"], \n",
    "                   linewidth=2, alpha=0.8, label=f\"{segment} path\")\n",
    "    \n",
    "    # Enhance plot appearance\n",
    "    ax.set_title(f\"Raw Tracking Trajectory: {filename}\", fontsize=16)\n",
    "    ax.set_xlabel(\"X Coordinate\", fontsize=14)\n",
    "    ax.set_ylabel(\"Y Coordinate\", fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(title=\"Segment\", fontsize=10)\n",
    "    \n",
    "    # Add note about coordinate system\n",
    "    ax.text(0.02, 0.02, \"Note: (0,0) is at top-left corner\", \n",
    "           transform=ax.transAxes, fontsize=10, alpha=0.7,\n",
    "           bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_cumulative_distance(filename, df, show_plot=True):\n",
    "    \"\"\"\n",
    "    Plot the cumulative distance traveled over time.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Name of the file being visualized\n",
    "        df (pd.DataFrame): DataFrame containing trajectory data\n",
    "        show_plot (bool): Whether to display the plot immediately\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=TIMELINE_FIGSIZE)\n",
    "    \n",
    "    # Plot cumulative distance as line\n",
    "    ax.plot(df[\"Frame\"], df[\"cumulative_distance\"], label=\"Cumulative Distance\", \n",
    "           color=\"green\", linewidth=2)\n",
    "    \n",
    "    # Add segment transitions as vertical lines\n",
    "    segment_changes = df['closest_segment'].ne(df['closest_segment'].shift()).cumsum()\n",
    "    change_frames = df.groupby(segment_changes)['Frame'].first().iloc[1:]\n",
    "    \n",
    "    for frame in change_frames:\n",
    "        ax.axvline(x=frame, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Add velocity information\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(df[\"Frame\"], df[\"velocity\"], label=\"Instantaneous Velocity\", \n",
    "            color=\"red\", alpha=0.3)\n",
    "    ax2.set_ylabel(\"Velocity (pixels/frame)\", color=\"red\", fontsize=14)\n",
    "    ax2.tick_params(axis='y', labelcolor=\"red\")\n",
    "    \n",
    "    # Enhance plot appearance\n",
    "    ax.set_title(f\"Cumulative Distance Over Time: {filename}\", fontsize=16)\n",
    "    ax.set_xlabel(\"Frame\", fontsize=14)\n",
    "    ax.set_ylabel(\"Cumulative Distance (pixels)\", fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Combine legends\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a764002-ba9a-4da1-bba8-2f49cfd3c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proportion_by_segment(filename, df, show_plot=True, highlight_peaks=True):\n",
    "    \"\"\"\n",
    "    Plot proportion values over time, colored by segment, with threshold lines.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Name of the file being visualized\n",
    "        df (pd.DataFrame): DataFrame containing trajectory data\n",
    "        show_plot (bool): Whether to display the plot immediately\n",
    "        highlight_peaks (bool): Whether to highlight detected peaks\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    # Create segment-specific DataFrames\n",
    "    df_bottom = df[df['closest_segment'] == \"bottom\"]\n",
    "    df_left = df[df['closest_segment'] == \"left\"]\n",
    "    df_right = df[df['closest_segment'] == \"right\"]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=TIMELINE_FIGSIZE)\n",
    "    \n",
    "    # Plot proportion values by segment\n",
    "    sns.scatterplot(x=df_left[\"Frame\"], y=df_left[\"proportion\"], \n",
    "                   label=\"Left\", color=SEGMENT_COLORS[\"left\"], ax=ax, alpha=0.6)\n",
    "    sns.scatterplot(x=df_right[\"Frame\"], y=df_right[\"proportion\"], \n",
    "                   label=\"Right\", color=SEGMENT_COLORS[\"right\"], ax=ax, alpha=0.6)\n",
    "    sns.scatterplot(x=df_bottom[\"Frame\"], y=df_bottom[\"proportion\"], \n",
    "                   label=\"Bottom\", color=SEGMENT_COLORS[\"bottom\"], ax=ax, alpha=0.6)\n",
    "    \n",
    "    # Connect points with lines\n",
    "    ax.plot(df[\"Frame\"], df[\"proportion\"], color='gray', alpha=0.2, linewidth=0.5)\n",
    "    \n",
    "    # Add threshold lines\n",
    "    ax.axhline(y=0.75, color='red', linestyle='--', linewidth=1.5)\n",
    "    ax.axhline(y=0.25, color='cyan', linestyle='--', linewidth=1.5)\n",
    "    ax.axhline(y=-0.75, color='red', linestyle='--', linewidth=1.5)\n",
    "    ax.axhline(y=-0.25, color='cyan', linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    # Highlight threshold zones\n",
    "    ax.axhspan(0.75, 1.0, alpha=0.1, color='red')\n",
    "    ax.axhspan(0.25, 0.75, alpha=0.1, color='cyan')\n",
    "    ax.axhspan(-0.25, 0.25, alpha=0.1, color='gray')\n",
    "    ax.axhspan(-0.75, -0.25, alpha=0.1, color='cyan')\n",
    "    ax.axhspan(-1.0, -0.75, alpha=0.1, color='red')\n",
    "    \n",
    "    # Add labels for threshold regions\n",
    "    ax.text(df[\"Frame\"].max() * 1.01, 0.9, \"Peak Right\", fontsize=10, va='center')\n",
    "    ax.text(df[\"Frame\"].max() * 1.01, 0.5, \"Transition Zone\", fontsize=10, va='center')\n",
    "    ax.text(df[\"Frame\"].max() * 1.01, 0.0, \"No Choice Zone\", fontsize=10, va='center')\n",
    "    ax.text(df[\"Frame\"].max() * 1.01, -0.5, \"Transition Zone\", fontsize=10, va='center')\n",
    "    ax.text(df[\"Frame\"].max() * 1.01, -0.9, \"Peak Left\", fontsize=10, va='center')\n",
    "    \n",
    "    # Highlight peaks if requested\n",
    "    if highlight_peaks:\n",
    "        count_left, count_right, peak_frames = count_peaks_by_segment(\n",
    "            df['proportion'], df['closest_segment'])\n",
    "        \n",
    "        if peak_frames:\n",
    "            peak_proportions = df.loc[peak_frames, 'proportion']\n",
    "            ax.scatter(peak_frames, peak_proportions, color='red', s=100, \n",
    "                      zorder=5, label=f\"Peaks (L:{count_left}, R:{count_right})\")\n",
    "    \n",
    "    # Enhance plot appearance\n",
    "    ax.set_title(f\"Proportion Values by Segment: {filename}\", fontsize=16)\n",
    "    ax.set_xlabel(\"Frame\", fontsize=14)\n",
    "    ax.set_ylabel(\"Proportion\", fontsize=14)\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35f450-3456-411c-9305-8e0418a22cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_trajectory(filename, df, show_plot=True, resolution=HEATMAP_RESOLUTION, smoothing_factor=HEATMAP_SMOOTHING):\n",
    "    \"\"\"\n",
    "    Create a smoother heatmap showing where the bumblebee spent most time,\n",
    "    with a blue-to-red colormap and faded trajectories.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Name of the file being visualized\n",
    "        df (pd.DataFrame): DataFrame containing trajectory data\n",
    "        show_plot (bool): Whether to display the plot immediately\n",
    "        resolution (int): Resolution of the heatmap grid (lower = smoother)\n",
    "        smoothing_factor (float): Gaussian smoothing sigma (higher = smoother)\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    \n",
    "    # Filter out NaN values\n",
    "    valid_df = df.dropna(subset=['X_raw', 'Y_raw'])\n",
    "    \n",
    "    if valid_df.empty:\n",
    "        print(f\"No valid trajectory data for {filename}\")\n",
    "        return None\n",
    "    \n",
    "    # Determine the boundaries of the plot\n",
    "    x_min, x_max = valid_df['X_raw'].min(), valid_df['X_raw'].max()\n",
    "    y_min, y_max = valid_df['Y_raw'].min(), valid_df['Y_raw'].max()\n",
    "    \n",
    "    # Add some margin\n",
    "    margin = 0.1\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= margin * x_range\n",
    "    x_max += margin * x_range\n",
    "    y_min -= margin * y_range\n",
    "    y_max += margin * y_range\n",
    "    \n",
    "    # Create a 2D histogram with lower resolution for smoother appearance\n",
    "    hist, x_edges, y_edges = np.histogram2d(\n",
    "        valid_df['X_raw'], valid_df['Y_raw'], \n",
    "        bins=[resolution, resolution], \n",
    "        range=[[x_min, x_max], [y_min, y_max]]\n",
    "    )\n",
    "    \n",
    "    # Apply Gaussian smoothing to make the heatmap smoother\n",
    "    hist_smooth = gaussian_filter(hist, sigma=smoothing_factor)\n",
    "    \n",
    "    # Apply logarithmic transformation to better visualize the distribution\n",
    "    hist_smooth = np.log1p(hist_smooth)  # log(1+x) to handle zeros\n",
    "    \n",
    "    # Create figure with black background for better contrast\n",
    "    fig, ax = plt.subplots(figsize=HEATMAP_FIGSIZE, facecolor='black')\n",
    "    ax.set_facecolor('black')\n",
    "    \n",
    "    # Create blue-to-red colormap\n",
    "    cmap = plt.cm.coolwarm\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(hist_smooth.T, extent=[x_min, x_max, y_max, y_min], \n",
    "                  origin='upper', cmap=cmap, interpolation='gaussian',\n",
    "                  aspect='auto', alpha=0.9)\n",
    "    \n",
    "    # Add the raw trajectory as very faint lines\n",
    "    ax.plot(valid_df['X_raw'], valid_df['Y_raw'], \n",
    "           color='white', alpha=0.1, linewidth=0.5)\n",
    "    \n",
    "    # Highlight segment paths with very light transparency\n",
    "    segment_colors = {'bottom': 'yellow', 'left': 'lime', 'right': 'magenta'}\n",
    "    \n",
    "    for segment, color in segment_colors.items():\n",
    "        segment_df = valid_df[valid_df['closest_segment'] == segment]\n",
    "        if not segment_df.empty:\n",
    "            ax.plot(segment_df['X_raw'], segment_df['Y_raw'], \n",
    "                   color=color, alpha=0.2, linewidth=1.0, label=segment)\n",
    "    \n",
    "    # Add colorbar with custom formatting\n",
    "    cbar = plt.colorbar(im, ax=ax, pad=0.01)\n",
    "    cbar.set_label('Visitation Frequency', fontsize=14, color='white')\n",
    "    cbar.ax.yaxis.set_tick_params(color='white')\n",
    "    cbar.outline.set_edgecolor('white')\n",
    "    plt.setp(plt.getp(cbar.ax, 'yticklabels'), color='white')\n",
    "    \n",
    "    # Enhance plot appearance\n",
    "    ax.set_title(f\"Bumblebee Visitation Heatmap: {filename}\", fontsize=18, color='white')\n",
    "    ax.set_xlabel(\"X Coordinate\", fontsize=14, color='white')\n",
    "    ax.set_ylabel(\"Y Coordinate\", fontsize=14, color='white')\n",
    "    ax.tick_params(colors='white')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('white')\n",
    "    \n",
    "    # Create custom legend with white text\n",
    "    legend = ax.legend(framealpha=0.7, facecolor='black', edgecolor='white', fontsize=12)\n",
    "    for text in legend.get_texts():\n",
    "        text.set_color('white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb722d-4344-48c8-9f0c-73e98c3c1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trajectory_animation(filename, df, output_file=None, fps=ANIMATION_FPS, dpi=ANIMATION_DPI):\n",
    "    \"\"\"\n",
    "    Create an animation of the bumblebee's trajectory over time.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Name of the file being visualized\n",
    "        df (pd.DataFrame): DataFrame containing trajectory data\n",
    "        output_file (str, optional): Path to save the animation (if None, animation is displayed)\n",
    "        fps (int): Frames per second for the animation\n",
    "        dpi (int): Resolution of the output animation\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.animation.FuncAnimation: The animation object\n",
    "    \"\"\"\n",
    "    # Filter out NaN values\n",
    "    valid_df = df.dropna(subset=['X_raw', 'Y_raw'])\n",
    "    \n",
    "    if valid_df.empty:\n",
    "        print(f\"No valid trajectory data for {filename}\")\n",
    "        return None\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=DEFAULT_FIGSIZE)\n",
    "    \n",
    "    # Determine axis limits\n",
    "    x_min, x_max = valid_df['X_raw'].min(), valid_df['X_raw'].max()\n",
    "    y_min, y_max = valid_df['Y_raw'].min(), valid_df['Y_raw'].max()\n",
    "    \n",
    "    # Add margins\n",
    "    margin = 0.1\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    ax.set_xlim(x_min - margin * x_range, x_max + margin * x_range)\n",
    "    ax.set_ylim(y_max + margin * y_range, y_min - margin * y_range)  # Inverted for image coordinates\n",
    "    \n",
    "    # Prepare segment colors\n",
    "    segment_colors = SEGMENT_COLORS\n",
    "    \n",
    "    # Plot the Y-tube structure (all segments)\n",
    "    for segment, color in segment_colors.items():\n",
    "        segment_df = valid_df[valid_df['closest_segment'] == segment]\n",
    "        if not segment_df.empty:\n",
    "            ax.plot(segment_df['X_raw'], segment_df['Y_raw'], \n",
    "                   color=color, alpha=0.2, linewidth=3, label=f\"{segment} path\")\n",
    "    \n",
    "    # Animation elements\n",
    "    trail_line, = ax.plot([], [], 'gray', alpha=0.5, linewidth=1)\n",
    "    bee_point, = ax.plot([], [], 'ro', markersize=8)\n",
    "    timer_text = ax.text(0.02, 0.96, '', transform=ax.transAxes, fontsize=12)\n",
    "    segment_text = ax.text(0.02, 0.91, '', transform=ax.transAxes, fontsize=12)\n",
    "    \n",
    "    # Create legend for segments\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=color, edgecolor='black', alpha=0.6, label=segment)\n",
    "        for segment, color in segment_colors.items()\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    # Set up plot details\n",
    "    ax.set_title(f\"Bumblebee Trajectory Animation: {filename}\", fontsize=16)\n",
    "    ax.set_xlabel(\"X Coordinate\", fontsize=14)\n",
    "    ax.set_ylabel(\"Y Coordinate\", fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subsample frames for smoother animation\n",
    "    # Use every Nth frame for animation\n",
    "    N = max(1, len(valid_df) // 300)  # Aim for around 300 frames\n",
    "    sampled_df = valid_df.iloc[::N].reset_index(drop=True)\n",
    "    \n",
    "    def init():\n",
    "        \"\"\"Initialize the animation\"\"\"\n",
    "        trail_line.set_data([], [])\n",
    "        bee_point.set_data([], [])\n",
    "        timer_text.set_text('')\n",
    "        segment_text.set_text('')\n",
    "        return trail_line, bee_point, timer_text, segment_text\n",
    "    \n",
    "    def update(frame):\n",
    "        \"\"\"Update the animation for each frame\"\"\"\n",
    "        current_frame = sampled_df.iloc[:frame+1]\n",
    "        \n",
    "        # Update trail\n",
    "        trail_line.set_data(current_frame['X_raw'], current_frame['Y_raw'])\n",
    "        \n",
    "        # Update current position\n",
    "        curr_pos = current_frame.iloc[-1]\n",
    "        bee_point.set_data([curr_pos['X_raw']], [curr_pos['Y_raw']])\n",
    "        \n",
    "        # Update text information\n",
    "        timer_text.set_text(f\"Frame: {curr_pos['Frame']}\")\n",
    "        segment_text.set_text(f\"Segment: {curr_pos['closest_segment']}\")\n",
    "        \n",
    "        # Set color based on current segment\n",
    "        segment = curr_pos['closest_segment']\n",
    "        bee_point.set_color(segment_colors.get(segment, 'red'))\n",
    "        \n",
    "        return trail_line, bee_point, timer_text, segment_text\n",
    "    \n",
    "    # Create animation\n",
    "    ani = FuncAnimation(fig, update, frames=len(sampled_df),\n",
    "                       init_func=init, blit=True, interval=1000/fps)\n",
    "    \n",
    "    # Save or display animation\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_file:\n",
    "        ani.save(output_file, writer='pillow', fps=fps, dpi=dpi)\n",
    "        print(f\"Animation saved to {output_file}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b7106-af30-4d77-9716-9d8204d942dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_trajectories(folder_path, output_folder=None, \n",
    "                              save_plots=False, save_animations=False):\n",
    "    \"\"\"\n",
    "    Process and visualize all trajectory files in the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing processed CSV files\n",
    "        output_folder (str, optional): Path to save visualizations (defaults to folder_path/visualizations)\n",
    "        save_plots (bool): Whether to save plots as PNG files\n",
    "        save_animations (bool): Whether to save animations as GIF files\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of visualization results\n",
    "    \"\"\"\n",
    "    # Create output folder if needed\n",
    "    if save_plots or save_animations:\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(folder_path, 'visualizations')\n",
    "        \n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        print(f\"Visualizations will be saved to: {output_folder}\")\n",
    "    \n",
    "    # Load all trajectory files\n",
    "    trajectory_list = load_processed_trajectories(folder_path)\n",
    "    if not trajectory_list:\n",
    "        print(\"No trajectory files found\")\n",
    "        return {}\n",
    "    \n",
    "    # Process each trajectory\n",
    "    results = {}\n",
    "    for filename, df in trajectory_list:\n",
    "        print(f\"\\nProcessing: {filename}\")\n",
    "        trajectory_name = filename.replace('processed_', '').replace('.csv', '')\n",
    "        result_dict = {}\n",
    "        \n",
    "        # Create basic name for output files\n",
    "        base_filename = os.path.join(output_folder, trajectory_name) if output_folder else None\n",
    "        \n",
    "        # Create visualizations\n",
    "        try:\n",
    "            # Raw trajectory plot\n",
    "            fig1 = plot_raw_trajectory(trajectory_name, df, show_plot=not save_plots)\n",
    "            result_dict['raw_trajectory'] = fig1\n",
    "            if save_plots and base_filename:\n",
    "                fig1.savefig(f\"{base_filename}_raw_trajectory.png\", dpi=DPI)\n",
    "                plt.close(fig1)\n",
    "            \n",
    "            # Cumulative distance plot\n",
    "            fig2 = plot_cumulative_distance(trajectory_name, df, show_plot=not save_plots)\n",
    "            result_dict['cumulative_distance'] = fig2\n",
    "            if save_plots and base_filename:\n",
    "                fig2.savefig(f\"{base_filename}_cumulative_distance.png\", dpi=DPI)\n",
    "                plt.close(fig2)\n",
    "            \n",
    "            # Proportion by segment plot\n",
    "            fig3 = plot_proportion_by_segment(trajectory_name, df, show_plot=not save_plots)\n",
    "            result_dict['proportion_plot'] = fig3\n",
    "            if save_plots and base_filename:\n",
    "                fig3.savefig(f\"{base_filename}_proportion.png\", dpi=DPI)\n",
    "                plt.close(fig3)\n",
    "            \n",
    "            # Heatmap trajectory\n",
    "            fig4 = plot_heatmap_trajectory(trajectory_name, df, show_plot=not save_plots)\n",
    "            result_dict['heatmap'] = fig4\n",
    "            if save_plots and base_filename and fig4:\n",
    "                fig4.savefig(f\"{base_filename}_heatmap.png\", dpi=DPI)\n",
    "                plt.close(fig4)\n",
    "            \n",
    "            # Animation (only if requested)\n",
    "            if save_animations and base_filename:\n",
    "                ani = create_trajectory_animation(\n",
    "                    trajectory_name, df, \n",
    "                    output_file=f\"{base_filename}_animation.gif\",\n",
    "                    fps=10, dpi=100\n",
    "                )\n",
    "                result_dict['animation'] = ani\n",
    "            \n",
    "            results[trajectory_name] = result_dict\n",
    "            print(f\"Completed visualizations for: {trajectory_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {trajectory_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nCompleted visualization of {len(results)} trajectory files\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7b205-8fe7-427b-a793-831058848624",
   "metadata": {},
   "source": [
    "### Visualization Configuration and Run\n",
    "\n",
    "This cell creates visualizations of the tracking results. It can generate various plots and animations to help understand the bumblebee's behavior.\n",
    "\n",
    "#### Key Parameters:\n",
    "- `VISUALIZATION_FOLDER`: Directory containing the processed CSV files\n",
    "- `OUTPUT_FOLDER`: Where to save visualizations (None = auto-create subfolder)\n",
    "- `SAVE_PLOTS`: Whether to save plot images to disk\n",
    "- `SAVE_ANIMATIONS`: Whether to create and save animations (GIF files)\n",
    "- `INTERACTIVE_DISPLAY`: Whether to display plots in the notebook\n",
    "- `VISUALIZE_ALL`: Process all trajectories or just specific ones\n",
    "- `SPECIFIC_FILES`: List of specific files to process (if not VISUALIZE_ALL)\n",
    "\n",
    "#### Instructions:\n",
    "1. Make sure you've completed the tracking step for all videos\n",
    "2. Configure the visualization parameters\n",
    "3. Run this cell to generate visualizations\n",
    "4. View the plots in the notebook or check the output folder\n",
    "\n",
    "#### Visualization Types:\n",
    "- Raw trajectory plots (spatial path with color-coded segments)\n",
    "- Cumulative distance plots (distance over time)\n",
    "- Proportion plots (time spent in each segment)\n",
    "- Heatmaps (spatial density of bumblebee positions)\n",
    "- Animations (dynamic visualization of movement, if enabled)\n",
    "\n",
    "#### Output:\n",
    "If saving is enabled, files will be named `<video_name>_<plot_type>.png` or `<video_name>_animation.gif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78263c6b-5f6e-4b7f-ac9d-492280384b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== VISUALIZATION EXECUTION =====\n",
    "# Modify these parameters for visualization settings\n",
    "\n",
    "# Directory and file settings\n",
    "VISUALIZATION_FOLDER = r'C:\\Users\\YourUsername\\Videos'  # Path to processed files\n",
    "OUTPUT_FOLDER = None                                  # Output folder (None = auto-create)\n",
    "\n",
    "# Output options\n",
    "SAVE_PLOTS = True                                   # Whether to save plots to disk\n",
    "SAVE_ANIMATIONS = True                               # Whether to create and save animations\n",
    "INTERACTIVE_DISPLAY = False                            # Whether to display plots interactively\n",
    "\n",
    "# Visualization subset\n",
    "VISUALIZE_ALL = True                                  # Process all trajectories\n",
    "SPECIFIC_FILES = []                                   # List of specific files to process\n",
    "# =====================================\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = VISUALIZATION_FOLDER\n",
    "    \n",
    "    print(f\"Starting visualization of trajectories in {folder_path}\")\n",
    "    \n",
    "    if VISUALIZE_ALL:\n",
    "        # Option 1: Visualize all trajectories\n",
    "        results = visualize_all_trajectories(\n",
    "            folder_path, \n",
    "            output_folder=OUTPUT_FOLDER,\n",
    "            save_plots=SAVE_PLOTS, \n",
    "            save_animations=SAVE_ANIMATIONS\n",
    "        )\n",
    "        \n",
    "        print(f\"Generated {len(results)} visualization sets\")\n",
    "    else:\n",
    "        # Option 2: Process specific trajectory files\n",
    "        processed_trajectories = load_processed_trajectories(folder_path)\n",
    "        \n",
    "        if SPECIFIC_FILES:\n",
    "            # Filter to specific files if requested\n",
    "            processed_trajectories = [(filename, df) for filename, df in processed_trajectories \n",
    "                                     if any(spec_file in filename for spec_file in SPECIFIC_FILES)]\n",
    "            \n",
    "        # Process each trajectory file\n",
    "        for filename, df in processed_trajectories:\n",
    "            print(f\"Visualizing {filename}\")\n",
    "            \n",
    "            # Create individual plots\n",
    "            raw_fig = plot_raw_trajectory(filename, df, show_plot=INTERACTIVE_DISPLAY)\n",
    "            proportion_fig = plot_proportion_by_segment(filename, df, show_plot=INTERACTIVE_DISPLAY)\n",
    "            \n",
    "            # Save plots if requested\n",
    "            if SAVE_PLOTS and OUTPUT_FOLDER:\n",
    "                output_path = os.path.join(OUTPUT_FOLDER if OUTPUT_FOLDER else folder_path, \n",
    "                                          f\"{filename.replace('.csv', '')}\")\n",
    "                raw_fig.savefig(f\"{output_path}_raw.png\", dpi=DPI)\n",
    "                proportion_fig.savefig(f\"{output_path}_proportion.png\", dpi=DPI)\n",
    "                print(f\"Saved plots to {output_path}_*.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d4baf-6178-44ce-ac5c-9029ba8c282d",
   "metadata": {},
   "source": [
    "## 5. Analysis & Metrics Computation\n",
    "\n",
    "This section calculates behavioral metrics from the tracking data and generates summary statistics. The analysis provides insights into bumblebee behavior in the Y-tube, such as preferences for different odors, movement patterns, and decision-making dynamics.\n",
    "\n",
    "### Analysis Process:\n",
    "1. Load tracking files for each video\n",
    "2. Calculate metrics such as segment preferences and velocity\n",
    "3. Merge with experimental metadata\n",
    "4. Generate summary statistics by experimental conditions\n",
    "5. Create visualization of results\n",
    "\n",
    "### Key Metrics:\n",
    "- Time and proportion spent in each Y-tube arm\n",
    "- Number and frequency of movements between arms\n",
    "- Velocity and acceleration patterns\n",
    "- First and final arm choices\n",
    "\n",
    "The results are saved to a CSV file for further analysis in statistical software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35022521-2578-4197-ad4b-a7999491d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ANALYSIS CONFIGURATION =====\n",
    "# Modify these parameters to configure the analysis process\n",
    "\n",
    "# Directory and file settings\n",
    "ANALYSIS_FOLDER = r'C:\\Users\\YourUsername\\Videos'  # Path to processed files\n",
    "METADATA_FILE = 'metadata_phtalates.csv'                        # Name of the metadata file \n",
    "OUTPUT_FOLDER = None                                  # Output folder (None = auto-create)\n",
    "OUTPUT_FILE = 'results.csv'                           # Name of the output results file\n",
    "\n",
    "# Filtering parameters\n",
    "MIN_DURATION = 6.0                                    # Minimum video duration (minutes)\n",
    "MAX_DURATION = 12.0                                   # Maximum video duration (minutes)\n",
    "MAX_BOTTOM_RATIO = 0.7                                # Maximum proportion in bottom segment\n",
    "\n",
    "# Analysis settings\n",
    "FPS = 10                                              # Frames per second (for time calculations)\n",
    "GROUP_COLUMN = 'MODA'                            # Main column for grouping results\n",
    "GENERATE_PLOTS = True                                 # Whether to generate summary plots\n",
    "SAVE_RESULTS = True                                  # Whether to save summary plots\n",
    "# ====================================\n",
    "\n",
    "# Main cell for analyzing insect olfactometer experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432d97c-cde8-43dc-80c8-0a207c4dced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "print(f\"Starting analysis of olfactometer data in {ANALYSIS_FOLDER}\")\n",
    "\n",
    "# Set output folder\n",
    "if OUTPUT_FOLDER is None:\n",
    "    OUTPUT_FOLDER = os.path.join(ANALYSIS_FOLDER, 'analysis')\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    print(f\"Created output directory: {OUTPUT_FOLDER}\")\n",
    "\n",
    "\n",
    "def remove_consecutive_duplicates(lst):\n",
    "    \"\"\"\n",
    "    Remove consecutive duplicate items from a list while preserving order.\n",
    "    \n",
    "    Args:\n",
    "        lst (list): List of items to process\n",
    "        \n",
    "    Returns:\n",
    "        list: List with consecutive duplicates removed\n",
    "    \"\"\"\n",
    "    if not lst:\n",
    "        return []\n",
    "    \n",
    "    result = [lst[0]]\n",
    "    for elem in lst[1:]:\n",
    "        if elem != result[-1]:  # Only add if different from the last element\n",
    "            result.append(elem)\n",
    "    return result\n",
    "\n",
    "\n",
    "def count_transition_patterns(segment_list):\n",
    "    \"\"\"\n",
    "    Count different transition patterns between segments.\n",
    "    \n",
    "    Args:\n",
    "        segment_list (list): List of segment labels\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with counts of different transition patterns\n",
    "    \"\"\"\n",
    "    patterns = {\n",
    "        \"left_no_choice_right\": 0,\n",
    "        \"right_no_choice_left\": 0,\n",
    "        \"right_no_choice_right\": 0,\n",
    "        \"left_no_choice_left\": 0,\n",
    "        \"bottom_no_choice_right\": 0,\n",
    "        \"bottom_no_choice_left\": 0\n",
    "    }\n",
    "\n",
    "    for i in range(len(segment_list) - 2):\n",
    "        # Check for each transition pattern\n",
    "        if segment_list[i] == \"left\" and segment_list[i+1] == \"no_choice\" and segment_list[i+2] == \"right\":\n",
    "            patterns[\"left_no_choice_right\"] += 1\n",
    "        elif segment_list[i] == \"right\" and segment_list[i+1] == \"no_choice\" and segment_list[i+2] == \"left\":\n",
    "            patterns[\"right_no_choice_left\"] += 1\n",
    "        elif segment_list[i] == \"right\" and segment_list[i+1] == \"no_choice\" and segment_list[i+2] == \"right\":\n",
    "            patterns[\"right_no_choice_right\"] += 1\n",
    "        elif segment_list[i] == \"left\" and segment_list[i+1] == \"no_choice\" and segment_list[i+2] == \"left\":\n",
    "            patterns[\"left_no_choice_left\"] += 1\n",
    "        elif segment_list[i] == \"bottom\" and segment_list[i+1] == \"no_choice\" and segment_list[i+2] == \"right\":\n",
    "            patterns[\"bottom_no_choice_right\"] += 1\n",
    "        elif segment_list[i] == \"bottom\" and segment_list[i+1] == \"no_choice\" and segment_list[i+2] == \"left\":\n",
    "            patterns[\"bottom_no_choice_left\"] += 1\n",
    "\n",
    "    return patterns\n",
    "\n",
    "\n",
    "def find_first_and_last_choice(segment_list):\n",
    "    \"\"\"\n",
    "    Find the first and last choice (left or right) in a sequence of segments.\n",
    "    \n",
    "    Args:\n",
    "        segment_list (list): List of segment labels\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (first_choice, last_choice) - The first and last \"left\" or \"right\" segments\n",
    "    \"\"\"\n",
    "    first_choice = None\n",
    "    last_choice = None\n",
    "\n",
    "    for item in segment_list:\n",
    "        if item in (\"left\", \"right\"):\n",
    "            if first_choice is None:\n",
    "                first_choice = item.capitalize()  # Store the first occurrence\n",
    "            last_choice = item.capitalize()  # Keep updating to get the last occurrence\n",
    "\n",
    "    return first_choice, last_choice\n",
    "\n",
    "\n",
    "def preprocess_trajectory_data(df, proportion_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Preprocess trajectory data by adjusting proportion values and marking no_choice zones.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing trajectory data\n",
    "        proportion_threshold (float): Threshold below which segments are marked as \"no_choice\"\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed DataFrame\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Convert left segment proportions to negative values\n",
    "    df_processed.loc[df_processed['closest_segment'] == 'left', 'proportion'] *= -1\n",
    "    \n",
    "    # Calculate velocity in proportion space\n",
    "    df_processed[\"velocity_prop\"] = np.sqrt(df_processed[\"proportion\"].diff()**2)\n",
    "    \n",
    "    # Mark low-proportion regions as \"no_choice\"\n",
    "    df_processed.loc[abs(df_processed[\"proportion\"]) < proportion_threshold, \"closest_segment\"] = \"no_choice\"\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8b57b-4db3-47a9-9e81-6730cfd3b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trajectory(df, file_name, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Analyze the insect trajectory data and compute various behavioral metrics.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing trajectory data\n",
    "        file_name (str): Name of the file being analyzed\n",
    "        threshold (float): Threshold for considering high proportion values\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Single-row DataFrame with calculated metrics\n",
    "    \"\"\"\n",
    "    # Validate required columns\n",
    "    required_columns = {'closest_segment', 'proportion', 'velocity', 'cumulative_distance', 'X_projected'}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"DataFrame must contain the following columns: {required_columns}\")\n",
    "    \n",
    "    # Initialize metrics dictionary\n",
    "    metrics = {}\n",
    "    \n",
    "    # Calculate segment-specific metrics\n",
    "    for segment in ['right', 'left']:\n",
    "        # Time spent in each segment\n",
    "        time_segment = df['closest_segment'].eq(segment).sum()\n",
    "        metrics[f\"time_{segment}\"] = time_segment\n",
    "\n",
    "        # Sum and average proportion above threshold\n",
    "        segment_high_prop = df.loc[\n",
    "            (df['closest_segment'] == segment) & (abs(df['proportion']) > threshold),\n",
    "            'proportion'\n",
    "        ]\n",
    "        sum_proportion = segment_high_prop.sum()\n",
    "        avg_proportion = sum_proportion / time_segment if time_segment > 0 else None\n",
    "        \n",
    "        metrics[f\"sum_proportion_{segment}\"] = sum_proportion\n",
    "        metrics[f\"avg_proportion_{segment}\"] = avg_proportion\n",
    "\n",
    "        # Count frames above threshold\n",
    "        time_above_threshold = len(segment_high_prop)\n",
    "        metrics[f\"time_above_threshold_{segment}\"] = time_above_threshold\n",
    "\n",
    "        # Cumulative distance and velocity metrics\n",
    "        cumulative_distance = df.loc[df['closest_segment'] == segment, 'velocity_prop'].sum()\n",
    "        \n",
    "        # Calculate velocity in transition zones (proportion between 0.25 and 0.5)\n",
    "        velocity = df.loc[\n",
    "            (df['closest_segment'] == segment) & \n",
    "            (df['proportion'].abs().between(0.25, 0.5)),\n",
    "            'velocity_prop'\n",
    "        ].mean()\n",
    "        \n",
    "        # Handle NaN values\n",
    "        if pd.isna(velocity):\n",
    "            velocity = 0\n",
    "            \n",
    "        metrics[f\"cumulative_distance_{segment}\"] = cumulative_distance\n",
    "        metrics[f\"velocity_{segment}\"] = velocity\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    total_time = metrics[\"time_right\"] + metrics[\"time_left\"]\n",
    "    total_time_above_threshold = metrics[\"time_above_threshold_right\"] + metrics[\"time_above_threshold_left\"]\n",
    "    \n",
    "    # Calculate proportion of time spent in each segment\n",
    "    metrics[\"prop_right\"] = metrics[\"time_right\"] / total_time if total_time > 0 else None\n",
    "    metrics[\"prop_left\"] = metrics[\"time_left\"] / total_time if total_time > 0 else None\n",
    "    \n",
    "    # Calculate distance and velocity metrics\n",
    "    total_cumulative_distance = metrics[\"cumulative_distance_left\"] + metrics[\"cumulative_distance_right\"]\n",
    "    \n",
    "    # Average velocity in branches (proportion between 0.25 and 0.75)\n",
    "    avg_velocity_branches = df.loc[\n",
    "        ((df['closest_segment'] == \"right\") | (df['closest_segment'] == \"left\")) &\n",
    "        (df['proportion'].abs().between(0.25, 0.75)),\n",
    "        'velocity_prop'\n",
    "    ].mean()\n",
    "    \n",
    "    # Overall average velocity in all branches\n",
    "    avg_velocity_total = df.loc[\n",
    "        ((df['closest_segment'] == \"right\") | (df['closest_segment'] == \"left\")),\n",
    "        'velocity_prop'\n",
    "    ].mean()\n",
    "    \n",
    "    metrics[\"cumulative_distance\"] = total_cumulative_distance\n",
    "    metrics[\"average_velocity_in_branch\"] = avg_velocity_branches\n",
    "    metrics[\"overall_average_velocity\"] = avg_velocity_total\n",
    "\n",
    "    # Calculate proportional distance metrics\n",
    "    if total_cumulative_distance > 0:\n",
    "        metrics['prop_cumulative_distance_left'] = metrics[\"cumulative_distance_left\"] / total_cumulative_distance\n",
    "        metrics['prop_cumulative_distance_right'] = metrics[\"cumulative_distance_right\"] / total_cumulative_distance\n",
    "    else:\n",
    "        metrics['prop_cumulative_distance_left'] = None\n",
    "        metrics['prop_cumulative_distance_right'] = None\n",
    "    \n",
    "    # Calculate proportion metrics\n",
    "    total_sum_proportion = abs(metrics[\"sum_proportion_right\"]) + abs(metrics[\"sum_proportion_left\"])\n",
    "    metrics[\"sum_proportion_total\"] = total_sum_proportion\n",
    "    \n",
    "    if total_sum_proportion != 0:\n",
    "        metrics[\"prop_proportion_left\"] = abs(metrics[\"sum_proportion_left\"]) / total_sum_proportion\n",
    "        metrics[\"prop_proportion_right\"] = abs(metrics[\"sum_proportion_right\"]) / total_sum_proportion\n",
    "\n",
    "    else:\n",
    "        metrics[\"prop_proportion_left\"] = None\n",
    "        metrics[\"prop_proportion_right\"] = None\n",
    "   \n",
    "    \n",
    "    # Calculate peak-related metrics\n",
    "    bout_left, bout_right, peak_times = count_peaks_by_segment(df['proportion'], df['closest_segment'])\n",
    "    \n",
    "    # Analyze segment transitions\n",
    "    segment_sequence = remove_consecutive_duplicates(df['closest_segment'].tolist())\n",
    "    transition_patterns = count_transition_patterns(segment_sequence)\n",
    "    first_choice_lr, last_choice_lr = find_first_and_last_choice(segment_sequence)\n",
    "    \n",
    "    # Store choice-related metrics\n",
    "    metrics[\"first_choice_lr\"] = first_choice_lr\n",
    "    metrics[\"last_choice_lr\"] = last_choice_lr\n",
    "    \n",
    "    # Store transition pattern counts\n",
    "    metrics[\"change_count\"] = transition_patterns[\"right_no_choice_left\"] + transition_patterns[\"left_no_choice_right\"]\n",
    "    metrics[\"baf_left\"] = transition_patterns[\"left_no_choice_left\"] + transition_patterns[\"bottom_no_choice_left\"]\n",
    "    metrics[\"baf_right\"] = transition_patterns[\"right_no_choice_right\"] + transition_patterns[\"bottom_no_choice_right\"]\n",
    "    \n",
    "    # Calculate back-and-forth indices\n",
    "    total_baf = metrics[\"baf_right\"] + metrics[\"baf_left\"]\n",
    "\n",
    "    # Store peak counts\n",
    "    metrics[\"bout_left\"] = bout_left\n",
    "    metrics[\"bout_right\"] = bout_right\n",
    "    \n",
    "    # Calculate peak-related indices\n",
    "    total_bout = bout_right + bout_left\n",
    "    if total_bout != 0:\n",
    "        metrics[\"prop_bout_left\"] = bout_left / total_bout\n",
    "        metrics[\"prop_bout_right\"] = bout_right / total_bout\n",
    "    else:\n",
    "        metrics[\"prop_bout_left\"] = None\n",
    "        metrics[\"prop_bout_right\"] = None\n",
    "    \n",
    "    # Print summary information\n",
    "    print(f\"{file_name}: Left prop = {metrics['prop_left']}, Right prop = {metrics['prop_right']}\")\n",
    "    \n",
    "    # Add file identifier to results\n",
    "    metrics[\"ID\"] = file_name\n",
    "    \n",
    "    # Return results as a single-row DataFrame\n",
    "    return pd.DataFrame([metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b23602-41f9-4fd6-a43d-2a15fbf1d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter_csv_files(folder_path, pattern=\"processed_*.mp4.csv\", \n",
    "                              min_duration=6.0, max_duration=12.0, max_bottom_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Load and filter processed CSV trajectory files based on specified criteria.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to folder containing CSV files\n",
    "        pattern (str): Pattern to match filenames\n",
    "        min_duration (float): Minimum duration in minutes (at 10fps)\n",
    "        max_duration (float): Maximum duration in minutes (at 10fps)\n",
    "        max_bottom_ratio (float): Maximum ratio of time spent in bottom segment\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (list of valid filenames, list of valid DataFrames, list of recording lengths)\n",
    "    \"\"\"\n",
    "    # Get all CSV files with the specified pattern\n",
    "    tracking_csv_files = [file for file in os.listdir(folder_path) \n",
    "                        if file.endswith(\".csv\") and \"processed_\" in file]\n",
    "    \n",
    "    if not tracking_csv_files:\n",
    "        print(f\"No tracking CSV files found in {folder_path}\")\n",
    "        return [], [], []\n",
    "    \n",
    "    print(f\"Found {len(tracking_csv_files)} tracking files\")\n",
    "    \n",
    "    # Initialize result lists\n",
    "    valid_files = []\n",
    "    valid_dfs = []\n",
    "    recording_lengths = []\n",
    "    \n",
    "    # Process each file\n",
    "    for csv_filename in tracking_csv_files:\n",
    "        csv_path = os.path.join(folder_path, csv_filename)\n",
    "        \n",
    "        try:\n",
    "            df_tracking = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Filter based on proportion of time in bottom segment\n",
    "            length_bottom = len(df_tracking.loc[df_tracking['closest_segment'] == 'bottom'])\n",
    "            length_of_recording = len(df_tracking)\n",
    "            bottom_ratio = length_bottom / length_of_recording if length_of_recording > 0 else 1.0\n",
    "            \n",
    "            # Convert frame count to minutes (assuming 10fps)\n",
    "            minutes = length_of_recording / (60 * 10)\n",
    "            \n",
    "            # Check if file meets criteria\n",
    "            if bottom_ratio > max_bottom_ratio:\n",
    "                print(f\"Skipping {csv_filename}: Too much time in bottom segment ({bottom_ratio:.1%})\")\n",
    "                continue\n",
    "                \n",
    "            if minutes < min_duration or minutes > max_duration:\n",
    "                print(f\"Skipping {csv_filename}: Duration ({minutes:.1f} min) outside range\")\n",
    "                continue\n",
    "            \n",
    "            # Extract file name without extension for later use\n",
    "            pattern = r'processed_(.+)\\.mp4'\n",
    "            match = re.search(pattern, csv_filename)\n",
    "            \n",
    "            if match:\n",
    "                file_name = match.group(1)  # Extract the content between \"processed_\" and \".mp4\"\n",
    "                \n",
    "                # Preprocess the data\n",
    "                df_processed = preprocess_trajectory_data(df_tracking)\n",
    "                \n",
    "                # Add to valid lists\n",
    "                valid_files.append(file_name)\n",
    "                valid_dfs.append(df_processed)\n",
    "                recording_lengths.append(length_of_recording)\n",
    "                \n",
    "                print(f\"Processed {file_name}: {minutes:.1f} min, {bottom_ratio:.1%} bottom\")\n",
    "            else:\n",
    "                print(f\"Skipping {csv_filename}: Filename does not match expected pattern\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {csv_filename}: {e}\")\n",
    "    \n",
    "    print(f\"Successfully loaded {len(valid_files)} valid tracking files\")\n",
    "    return valid_files, valid_dfs, recording_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f34c93-7bd5-449e-b9d3-3dc0c2921d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correspondance_df(df):\n",
    "    \"\"\"\n",
    "    Convert left/right metrics to odor/control metrics based on which \n",
    "    side contained the odor treatment.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with metrics and 'Cote_Odor' column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with metrics reorganized by treatment\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    \n",
    "    # Mapping dictionaries for each orientation\n",
    "    left_odor_mapping = {\n",
    "        'time_left': 'time_odor',\n",
    "        'prop_left': 'prop_odor',\n",
    "        'sum_proportion_left': 'sum_proportion_odor',\n",
    "        'avg_proportion_left': 'avg_proportion_odor',\n",
    "        'time_right': 'time_control',\n",
    "        'prop_right': 'prop_control',\n",
    "        'sum_proportion_right': 'sum_proportion_control',\n",
    "        'avg_proportion_right': 'avg_proportion_control',\n",
    "        'time_above_threshold_left': 'time_odor_above_threshold',\n",
    "        'time_above_threshold_right': 'time_control_above_threshold',\n",
    "        'cumulative_distance_left': 'cumulative_distance_odor',\n",
    "        'cumulative_distance_right': 'cumulative_distance_control',\n",
    "        'prop_cumulative_distance_left': 'prop_cumulative_distance_odor',\n",
    "        'velocity_left': 'average_velocity_odor',\n",
    "        'velocity_right': 'average_velocity_control',\n",
    "        'bout_left': 'bout_odor',\n",
    "        'bout_right': 'bout_control',\n",
    "        'prop_bout_left': 'prop_bout_odor',\n",
    "        'prop_bout_right': 'prop_bout_control',\n",
    "        'prop_proportion_left': 'prop_proportion_odor',\n",
    "        'prop_proportion_right': 'prop_proportion_control',\n",
    "        'prop_cumulative_distance_left': 'prop_cumultive_distance_odor',\n",
    "    }\n",
    "    \n",
    "    right_odor_mapping = {\n",
    "        'time_right': 'time_odor',\n",
    "        'prop_right': 'prop_odor',\n",
    "        'sum_proportion_right': 'sum_proportion_odor',\n",
    "        'avg_proportion_right': 'avg_proportion_odor',\n",
    "        'time_left': 'time_control',\n",
    "        'prop_left': 'prop_control',\n",
    "        'sum_proportion_left': 'sum_proportion_control',\n",
    "        'avg_proportion_left': 'avg_proportion_control',\n",
    "        'time_above_threshold_right': 'time_odor_above_threshold',\n",
    "        'time_above_threshold_left': 'time_control_above_threshold',\n",
    "        'cumulative_distance_right': 'cumulative_distance_odor',\n",
    "        'cumulative_distance_left': 'cumulative_distance_control',\n",
    "        'prop_cumulative_distance_right': 'prop_cumulative_distance_odor',\n",
    "        'velocity_right': 'average_velocity_odor',\n",
    "        'velocity_left': 'average_velocity_control',\n",
    "        'bout_right': 'bout_odor',\n",
    "        'bout_left': 'bout_control',\n",
    "        'prop_bout_right': 'prop_bout_odor',\n",
    "        'prop_bout_left': 'prop_bout_control',\n",
    "        'prop_proportion_right': 'prop_proportion_odor',\n",
    "        'prop_proportion_left': 'prop_proportion_control',\n",
    "        'prop_cumulative_distance_right': 'prop_cumultive_distance_odor',\n",
    "    }\n",
    "    \n",
    "    # Process each row\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            if row.get('Cote_Odor') == 'Left':\n",
    "                # Map metrics based on left odor\n",
    "                for source, target in left_odor_mapping.items():\n",
    "                    if source in row and pd.notna(row[source]):\n",
    "                        df_result.at[index, target] = row[source]\n",
    "                \n",
    "                \n",
    "                # First and last choice\n",
    "                if row['first_choice_lr'] == \"Left\":  # Left\n",
    "                    df_result.at[index, 'first_choice'] = \"Odor\"  # Chose odor\n",
    "                else:\n",
    "                    df_result.at[index, 'first_choice'] = \"Control\"  # Did not choose odor\n",
    "                    \n",
    "                if row['last_choice_lr'] == \"Left\":  # Left\n",
    "                    df_result.at[index, 'last_choice'] = \"Odor\"  # Ended on odor\n",
    "                else:\n",
    "                    df_result.at[index, 'last_choice'] = \"Control\"  # Did not end on odor\n",
    "                    \n",
    "            elif row.get('Cote_Odor') == 'Right':\n",
    "                # Map metrics based on right odor\n",
    "                for source, target in right_odor_mapping.items():\n",
    "                    if source in row and pd.notna(row[source]):\n",
    "                        df_result.at[index, target] = row[source]\n",
    "                \n",
    "           \n",
    "           \n",
    "                \n",
    "                # First and last choice\n",
    "                if row['first_choice_lr'] == \"Right\":  # Right\n",
    "                    df_result.at[index, 'first_choice'] = \"Odor\"  # Chose odor\n",
    "                else:\n",
    "                    df_result.at[index, 'first_choice'] = \"Control\" # Did not choose odor\n",
    "                    \n",
    "                if row['last_choice_lr'] == \"Right\":  # Right\n",
    "                    df_result.at[index, 'last_choice'] = \"Odor\" # Ended on odor\n",
    "                else:\n",
    "                    df_result.at[index, 'last_choice'] = \"Control\" # Did not end on odor\n",
    "                    \n",
    "            else:\n",
    "                print(f\"Warning: Unknown Cote_Odor value '{row.get('Cote_Odor')}' for index {index}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c49914-b264-463a-af14-9f842cd8e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_statistics(df, group_columns=None, metric_columns=None):\n",
    "    \"\"\"\n",
    "    Generate summary statistics for behavioral metrics.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with behavioral metrics\n",
    "        group_columns (list): Columns to group by (e.g., ['Dose', 'Treatment', Genotype','Condition'])\n",
    "        metric_columns (list): Metrics to summarize (if None, use common behavior metrics)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Summary statistics DataFrame\n",
    "    \"\"\"\n",
    "    # Default grouping if none provided\n",
    "    if group_columns is None:\n",
    "        # Try to find common grouping columns\n",
    "        potential_groups = ['Dose', 'Treatment', 'Hive', 'Cov','Genotype','Condition']\n",
    "        group_columns = [col for col in potential_groups if col in df.columns]\n",
    "        \n",
    "        if not group_columns:\n",
    "            print(\"No grouping columns found. Using all data as one group.\")\n",
    "            group_columns = []\n",
    "    \n",
    "    # Default metrics if none provided\n",
    "    if metric_columns is None:\n",
    "        # Common behavior metrics to analyze\n",
    "        metric_columns = [\n",
    "        'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "        ]\n",
    "    \n",
    "    # Available metrics\n",
    "    available_metrics = [col for col in metric_columns if col in df.columns]\n",
    "    \n",
    "    if not available_metrics:\n",
    "        print(\"Warning: None of the specified metrics are in the DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    summary_stats = []\n",
    "    \n",
    "    # Handle the case with no grouping\n",
    "    if not group_columns:\n",
    "        stat_dict = {'Group': 'All Data', 'Count': len(df)}\n",
    "        \n",
    "        # Calculate statistics for each metric\n",
    "        for metric in available_metrics:\n",
    "            data = df[metric].dropna()\n",
    "            if len(data) > 0:\n",
    "                stat_dict[f'{metric}_mean'] = data.mean()\n",
    "                stat_dict[f'{metric}_median'] = data.median()\n",
    "                stat_dict[f'{metric}_std'] = data.std()\n",
    "                stat_dict[f'{metric}_sem'] = data.sem()\n",
    "                stat_dict[f'{metric}_n'] = len(data)\n",
    "                \n",
    "        summary_stats.append(stat_dict)\n",
    "    else:\n",
    "        # Group data and calculate statistics\n",
    "        grouped = df.groupby(group_columns)\n",
    "        \n",
    "        for name, group in grouped:\n",
    "            # Handle different group types\n",
    "            if isinstance(name, tuple):\n",
    "                group_name = ' - '.join([str(x) for x in name])\n",
    "                stat_dict = {group_col: val for group_col, val in zip(group_columns, name)}\n",
    "            else:\n",
    "                group_name = str(name)\n",
    "                stat_dict = {group_columns[0]: name}\n",
    "                \n",
    "            stat_dict['Group'] = group_name\n",
    "            stat_dict['Count'] = len(group)\n",
    "            \n",
    "            # Calculate statistics for each metric\n",
    "            for metric in available_metrics:\n",
    "                data = group[metric].dropna()\n",
    "                if len(data) > 0:\n",
    "                    stat_dict[f'{metric}_mean'] = data.mean()\n",
    "                    stat_dict[f'{metric}_median'] = data.median()\n",
    "                    stat_dict[f'{metric}_std'] = data.std()\n",
    "                    stat_dict[f'{metric}_sem'] = data.sem()\n",
    "                    stat_dict[f'{metric}_n'] = len(data)\n",
    "                    \n",
    "            summary_stats.append(stat_dict)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a2d29d-26ad-4877-bbe0-7e21d2ec1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_behavioral_metrics(df, metrics=None, group_col=None, title=None, \n",
    "                                output_file=None, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Create a set of visualizations for behavioral metrics from olfactometer experiments.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with behavioral metrics\n",
    "        metrics (list): List of metrics to visualize (if None, use key metrics)\n",
    "        group_col (str): Column to use for grouping (e.g., 'Treatment', 'DOSE')\n",
    "        title (str): Title prefix for the plots\n",
    "        output_file (str): Path to save the figure (if None, display instead)\n",
    "        figsize (tuple): Figure size (width, height) in inches\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    # Default metrics if none provided\n",
    "    if metrics is None:\n",
    "        # Try to find key metrics\n",
    "        potential_metrics = [\n",
    "        'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "        ]\n",
    "        metrics = [m for m in potential_metrics if m in df.columns]\n",
    "        \n",
    "        if not metrics:\n",
    "            print(\"No suitable metrics found for visualization.\")\n",
    "            return None\n",
    "    \n",
    "    # Filter to available metrics\n",
    "    metrics = [m for m in metrics if m in df.columns]\n",
    "    \n",
    "    # Detect group column if not specified\n",
    "    if group_col is None:\n",
    "        potential_groups = ['Dose', 'Treatment', 'Hive', 'Cov','Genotype','Condition']\n",
    "        for col in potential_groups:\n",
    "            if col in df.columns and df[col].nunique() > 1:\n",
    "                group_col = col\n",
    "                break\n",
    "    \n",
    "    # Set up figure\n",
    "    n_metrics = len(metrics)\n",
    "    n_cols = min(3, n_metrics)\n",
    "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    if n_metrics == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Create a plot for each metric\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        if group_col:\n",
    "            # Group data\n",
    "            sns.boxplot(x=group_col, y=metric, data=df, ax=ax)\n",
    "            \n",
    "            # Add individual points\n",
    "            sns.stripplot(x=group_col, y=metric, data=df, \n",
    "                        size=4, color='black', alpha=0.5, ax=ax)\n",
    "            \n",
    "            # Rotate x-labels if many groups\n",
    "            if df[group_col].nunique() > 4:\n",
    "                plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "        else:\n",
    "            # Single group, just show distribution\n",
    "            sns.boxplot(y=metric, data=df, ax=ax)\n",
    "            sns.stripplot(y=metric, data=df, size=4, color='black', alpha=0.5, ax=ax)\n",
    "\n",
    "        # Add reference line at 0.5 for proportion metrics\n",
    "        if metric.startswith('prop_') :\n",
    "            ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Add title and labels\n",
    "        metric_name = metric.replace('_', ' ').title()\n",
    "        ax.set_title(metric_name)\n",
    "        ax.set_ylabel(metric_name)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    # Add overall title\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16, y=1.02)\n",
    "    else:\n",
    "        fig.suptitle('Behavioral Metrics Summary', fontsize=16, y=1.02)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Figure saved to {output_file}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_pairplot(df, vars=None, hue=None, figsize=(18, 18), title=None):\n",
    "    \"\"\"\n",
    "    Create a pairplot (scatter plot matrix) of multiple behavioral metrics.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with behavioral metrics\n",
    "        vars (list): List of variables to include in the pairplot\n",
    "        hue (str): Column to use for coloring points (e.g., 'Treatment')\n",
    "        figsize (tuple): Figure size\n",
    "        title (str): Title for the plot\n",
    "        \n",
    "    Returns:\n",
    "        seaborn.PairGrid: The generated pairplot\n",
    "    \"\"\"\n",
    "    # Default variables if none specified\n",
    "    if vars is None:\n",
    "        potential_vars = [\n",
    "        'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "        ]\n",
    "        vars = [v for v in potential_vars if v in df.columns]\n",
    "        \n",
    "    # Filter to available variables\n",
    "    vars = [v for v in vars if v in df.columns]\n",
    "    \n",
    "    if len(vars) < 2:\n",
    "        print(\"Not enough variables for pairplot\")\n",
    "        return None\n",
    "    \n",
    "    # Create pairplot with fill instead of shade (to fix the deprecation warning)\n",
    "    g = sns.pairplot(df, vars=vars, hue=hue, \n",
    "                   height=figsize[0]//len(vars),\n",
    "                   diag_kind='kde', \n",
    "                   plot_kws={'alpha': 0.6, 's': 80, 'edgecolor': 'w'},\n",
    "                   diag_kws={'fill': True})  # Using fill instead of shade to avoid deprecation warning\n",
    "    \n",
    "    # Add title if provided\n",
    "    if title:\n",
    "        g.fig.suptitle(title, fontsize=16, y=1.02)\n",
    "    \n",
    "    # Format axis labels\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.set_xlabel(ax.get_xlabel().replace('_', ' ').title())\n",
    "        ax.set_ylabel(ax.get_ylabel().replace('_', ' ').title())\n",
    "    \n",
    "    # Adjust layout\n",
    "    g.fig.tight_layout()\n",
    "    \n",
    "    return g\n",
    "\n",
    "\n",
    "def create_heatmap_by_treatment(df, metrics=None, treatment_col=None, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Create a heatmap comparing metrics across different treatment groups.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with behavioral metrics\n",
    "        metrics (list): List of metrics to include\n",
    "        treatment_col (str): Column containing treatment groups\n",
    "        figsize (tuple): Figure size\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    # Default metrics if none provided\n",
    "    if metrics is None:\n",
    "        potential_metrics = [\n",
    "        'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "        ]\n",
    "        metrics = [m for m in potential_metrics if m in df.columns]\n",
    "    \n",
    "    # Filter to available metrics\n",
    "    metrics = [m for m in metrics if m in df.columns]\n",
    "    \n",
    "    if len(metrics) < 2:\n",
    "        print(\"Not enough metrics for heatmap\")\n",
    "        return None\n",
    "    \n",
    "    # Detect treatment column if not specified\n",
    "    if treatment_col is None:\n",
    "        for col in ['Dose', 'Treatment', 'Hive', 'Cov','Genotype','Condition']:\n",
    "            if col in df.columns and df[col].nunique() > 1:\n",
    "                treatment_col = col\n",
    "                break\n",
    "    \n",
    "    if treatment_col is None or treatment_col not in df.columns:\n",
    "        print(\"No suitable treatment column found\")\n",
    "        return None\n",
    "    \n",
    "    # Aggregate data by treatment\n",
    "    grouped_data = df.groupby(treatment_col)[metrics].mean()\n",
    "    \n",
    "    # Convert data for better visualization\n",
    "    for col in grouped_data.columns:\n",
    "        # Center proportion metrics around 0.5\n",
    "        if col.startswith('prop_') and 'index' not in col:\n",
    "            grouped_data[col] = grouped_data[col] - 0.5\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = sns.heatmap(grouped_data, annot=True, cmap='coolwarm', center=0,\n",
    "                        linewidths=.5, fmt='.2f', cbar=True, ax=ax)\n",
    "    \n",
    "    # Format axis labels\n",
    "    ax.set_title(f'Behavioral Metrics by {treatment_col}', fontsize=16)\n",
    "    \n",
    "    # Format y-tick labels if they're long\n",
    "    if max(len(str(x)) for x in grouped_data.index) > 10:\n",
    "        plt.yticks(rotation=0)\n",
    "    \n",
    "    # Rename metrics for display\n",
    "    ax.set_xticklabels([x.replace('_', ' ').title() for x in grouped_data.columns], \n",
    "                     rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_radar_chart(df, metrics=None, group_col=None, figsize=(12, 10)):\n",
    "    \"\"\"\n",
    "    Create a radar chart comparing metrics across different treatment groups.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with behavioral metrics\n",
    "        metrics (list): List of metrics to include\n",
    "        group_col (str): Column for grouping\n",
    "        figsize (tuple): Figure size\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    # Default metrics if none provided\n",
    "    if metrics is None:\n",
    "        potential_metrics = [\n",
    "        'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "        ]\n",
    "        metrics = [m for m in potential_metrics if m in df.columns]\n",
    "    \n",
    "    # Filter to available metrics\n",
    "    metrics = [m for m in metrics if m in df.columns]\n",
    "    \n",
    "    if len(metrics) < 3:\n",
    "        print(\"At least 3 metrics are needed for a radar chart\")\n",
    "        return None\n",
    "    \n",
    "    # Detect group column if not specified\n",
    "    if group_col is None:\n",
    "        for col in ['Dose', 'Treatment', 'Hive', 'Cov','Genotype','Condition']:\n",
    "            if col in df.columns and df[col].nunique() > 1 and df[col].nunique() <= 6:\n",
    "                group_col = col\n",
    "                break\n",
    "    \n",
    "    if group_col is None or group_col not in df.columns:\n",
    "        print(\"No suitable grouping column found\")\n",
    "        return None\n",
    "    \n",
    "    # Group data\n",
    "    grouped_data = df.groupby(group_col)[metrics].mean()\n",
    "    \n",
    "    # Normalize data between 0 and 1 for radar chart\n",
    "    normalized_data = pd.DataFrame(index=grouped_data.index)\n",
    "    \n",
    "    for col in metrics:\n",
    "        # For proportion metrics already between 0-1, use as is\n",
    "        if col.startswith('prop_') and not col.endswith('index'):\n",
    "            normalized_data[col] = grouped_data[col]\n",
    "        # For other metrics, normalize min-max\n",
    "        else:\n",
    "            min_val = grouped_data[col].min()\n",
    "            max_val = grouped_data[col].max()\n",
    "            if max_val > min_val:\n",
    "                normalized_data[col] = (grouped_data[col] - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                normalized_data[col] = 0.5\n",
    "    \n",
    "    # Set up figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111, polar=True)\n",
    "    \n",
    "    # Number of metrics\n",
    "    N = len(metrics)\n",
    "    \n",
    "    # Compute angle for each metric\n",
    "    angles = [n / N * 2 * np.pi for n in range(N)]\n",
    "    angles += angles[:1]  # Close the loop\n",
    "    \n",
    "    # Set up radar chart\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "    \n",
    "    # Set up axis labels\n",
    "    plt.xticks(angles[:-1], [m.replace('_', ' ').title() for m in metrics], \n",
    "              fontsize=12)\n",
    "    \n",
    "    # Draw axis lines\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.25, 0.5, 0.75], [\"0.25\", \"0.5\", \"0.75\"], \n",
    "              color=\"grey\", size=10)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Plot each group\n",
    "    for i, group in enumerate(normalized_data.index):\n",
    "        values = normalized_data.loc[group].values.flatten().tolist()\n",
    "        values += values[:1]  # Close the loop\n",
    "        \n",
    "        # Plot data\n",
    "        ax.plot(angles, values, linewidth=2, linestyle='solid', \n",
    "               label=str(group))\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    \n",
    "    # Add title\n",
    "    plt.title(f'Behavioral Metrics by {group_col}', size=16, y=1.1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_correlation_matrix(df, metrics=None, method='pearson', cmap='coolwarm', \n",
    "                             figsize=(10, 8), title=None):\n",
    "    \"\"\"\n",
    "    Create a correlation matrix visualization for behavioral metrics.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with behavioral metrics\n",
    "        metrics (list): List of metrics to include in correlation (if None, use numeric columns)\n",
    "        method (str): Correlation method ('pearson', 'spearman', or 'kendall')\n",
    "        cmap (str): Colormap for the heatmap\n",
    "        figsize (tuple): Figure size\n",
    "        title (str): Plot title\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    # Select metrics if not specified\n",
    "    if metrics is None:\n",
    "        # Use numeric columns excluding IDs and metadata\n",
    "        exclude_cols = ['ID', 'Frame', 'X_raw', 'Y_raw', 'X_projected', 'Y_projected']\n",
    "        metrics = [col for col in df.select_dtypes(include=[np.number]).columns \n",
    "                  if not any(ex in col for ex in exclude_cols)]\n",
    "    else:\n",
    "        # Filter to available metrics\n",
    "        metrics = [m for m in metrics if m in df.columns]\n",
    "    \n",
    "    # Check if we have enough metrics\n",
    "    if len(metrics) < 2:\n",
    "        print(\"Not enough metrics for correlation analysis.\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[metrics].corr(method=method)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Create heatmap\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Mask upper triangle\n",
    "    sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmin=-1, vmax=1, \n",
    "               center=0, square=True, linewidths=.5, annot=True, fmt='.2f',\n",
    "               cbar_kws={\"shrink\": .7}, ax=ax)\n",
    "    \n",
    "    # Set title\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=14, pad=20)\n",
    "    else:\n",
    "        ax.set_title(f'{method.capitalize()} Correlation Matrix', fontsize=14, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_comparison_dashboard(df, group_col=None, output_folder=None):\n",
    "    \"\"\"\n",
    "    Create a comprehensive dashboard of visualizations for comparing groups.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with behavioral metrics\n",
    "        group_col (str): Column to use for grouping\n",
    "        output_folder (str): Folder to save visualizations\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of generated figures\n",
    "    \"\"\"\n",
    "    # Detect group column if not specified\n",
    "    if group_col is None:\n",
    "        potential_groups = ['Dose', 'Treatment', 'Hive', 'Cov','Genotype','Condition']\n",
    "        for col in potential_groups:\n",
    "            if col in df.columns and df[col].nunique() > 1:\n",
    "                group_col = col\n",
    "                break\n",
    "    \n",
    "    if group_col is None or group_col not in df.columns:\n",
    "        print(\"No suitable grouping column found. Cannot create comparison dashboard.\")\n",
    "        return None\n",
    "    \n",
    "    # Create output folder if specified and doesn't exist\n",
    "    if output_folder and not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Dictionary to store figures\n",
    "    figures = {}\n",
    "    \n",
    "    # 1. Key behavioral metrics visualization\n",
    "    key_metrics = [\n",
    "        'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available metrics\n",
    "    key_metrics = [m for m in key_metrics if m in df.columns]\n",
    "    \n",
    "    if key_metrics:\n",
    "        fig1 = visualize_behavioral_metrics(\n",
    "            df, metrics=key_metrics, group_col=group_col,\n",
    "            title=f\"Key Behavioral Metrics by {group_col}\",\n",
    "            figsize = (24,24)\n",
    "        )\n",
    "        figures['key_metrics'] = fig1\n",
    "\n",
    "    # 2. Heatmap by treatment\n",
    "    heatmap_metrics = [\n",
    "        'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available metrics\n",
    "    heatmap_metrics = [m for m in heatmap_metrics if m in df.columns]\n",
    "    \n",
    "    if heatmap_metrics:\n",
    "        fig2 = create_heatmap_by_treatment(\n",
    "            df, metrics=heatmap_metrics, treatment_col=group_col,\n",
    "            figsize=(14, 8)\n",
    "        )\n",
    "        figures['heatmap'] = fig2\n",
    "        \n",
    "    \n",
    "    # 3. Radar chart\n",
    "    radar_metrics = [\n",
    "        'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available metrics\n",
    "    radar_metrics = [m for m in radar_metrics if m in df.columns]\n",
    "    \n",
    "    if len(radar_metrics) >= 3:\n",
    "        fig3 = create_radar_chart(\n",
    "            df, metrics=radar_metrics, group_col=group_col,\n",
    "            figsize=(10, 10)\n",
    "        )\n",
    "        figures['radar'] = fig3\n",
    "    \n",
    "    # 4. Pairplot of key metrics\n",
    "    pairplot_metrics = [\n",
    "                'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available metrics\n",
    "    pairplot_metrics = [m for m in pairplot_metrics if m in df.columns]\n",
    "    \n",
    "    if len(pairplot_metrics) >= 2:\n",
    "        g =  create_pairplot(\n",
    "    final_df, vars=pairplot_metrics, hue=group_cols[0],\n",
    "    figsize=(24, 24),  # Much larger pairplot\n",
    "    title=f\"Relationships Between Key Metrics by {group_cols[0]}\"\n",
    ")\n",
    "        figures['pairplot'] = g\n",
    "    \n",
    "    # 5. Correlation matrix\n",
    "    correlation_metrics = [\n",
    "        'prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "        'prop_left','prop_bout_left','prop_proportion_left',\n",
    "        'average_velocity_in_branch','overall_average_velocity'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available metrics\n",
    "    correlation_metrics = [m for m in correlation_metrics if m in df.columns]\n",
    "    \n",
    "    if len(correlation_metrics) >= 3:\n",
    "        fig5 = create_correlation_matrix(\n",
    "            df, metrics=correlation_metrics,\n",
    "            title=\"Correlation Between Behavioral Metrics\",\n",
    "            figsize=(12, 10)\n",
    "        )\n",
    "        figures['correlation'] = fig5\n",
    "    \n",
    "    return figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c5031-3a41-42d5-8924-6e820740ac9b",
   "metadata": {},
   "source": [
    "### Analysis Configuration and Run\n",
    "\n",
    "This cell analyzes the tracking data to extract behavioral metrics and generate summary statistics. It calculates various metrics related to bumblebee preferences, movement patterns, and decision-making in the Y-tube.\n",
    "\n",
    "#### Key Parameters:\n",
    "- `ANALYSIS_FOLDER`: Directory containing the processed CSV files\n",
    "- `METADATA_FILE`: Filename of the experimental metadata CSV\n",
    "- `OUTPUT_FOLDER`: Where to save results (None = auto-create subfolder)\n",
    "- `OUTPUT_FILE`: Filename for the results CSV\n",
    "- `MIN_DURATION`, `MAX_DURATION`: Filter videos by duration (minutes)\n",
    "- `MAX_BOTTOM_RATIO`: Maximum allowable time in bottom segment\n",
    "- `FPS`: Frames per second (for time calculations)\n",
    "- `GROUP_COLUMN`: Main column for grouping in summary statistics\n",
    "- `GENERATE_PLOTS`: Whether to create summary plots\n",
    "\n",
    "#### Instructions:\n",
    "1. Make sure you've completed the tracking step for all videos\n",
    "2. Ensure your metadata file is in the correct format and location\n",
    "3. Configure the analysis parameters\n",
    "4. Run this cell to perform the analysis\n",
    "5. Review the summary statistics in the output\n",
    "6. Check the output folder for the results files\n",
    "\n",
    "#### Analysis Process:\n",
    "1. Load and filter tracking files based on criteria\n",
    "2. Calculate metrics for each trajectory\n",
    "3. Merge with experimental metadata (e.g., odor treatments)\n",
    "4. Convert left/right metrics to odor/control metrics\n",
    "5. Generate summary statistics by experimental conditions\n",
    "6. Save results to CSV files\n",
    "\n",
    "#### Output Files:\n",
    "- `results.csv`: Complete results for all videos\n",
    "- `summary_statistics.csv`: Statistical summary by experimental groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81ae32-993f-457d-ba91-55a00c19672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and filter tracking files\n",
    "print(\"\\n== STEP 1: Loading and filtering tracking files ==\")\n",
    "valid_files, valid_dfs, recording_lengths = load_and_filter_csv_files(\n",
    "    ANALYSIS_FOLDER,\n",
    "    min_duration=MIN_DURATION,       # Minimum recording duration in minutes\n",
    "    max_duration=MAX_DURATION,       # Maximum recording duration in minutes\n",
    "    max_bottom_ratio=MAX_BOTTOM_RATIO    # Maximum proportion of time in bottom segment\n",
    ")\n",
    "\n",
    "print(f\"Successfully loaded {len(valid_files)} valid tracking files\")\n",
    "if not valid_files:\n",
    "    print(\"No valid files found. Analysis cannot continue.\")\n",
    "else:\n",
    "    # Step 2: Analyze each trajectory\n",
    "    print(\"\\n== STEP 2: Analyzing trajectories ==\")\n",
    "    df_results_list = []\n",
    "    \n",
    "    for file_name, df in zip(valid_files, valid_dfs):\n",
    "        try:\n",
    "            # Analyze the trajectory\n",
    "            result_df = analyze_trajectory(df, file_name)\n",
    "            df_results_list.append(result_df)\n",
    "            print(f\"Analyzed {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {file_name}: {e}\")\n",
    "    \n",
    "    # Combine all results\n",
    "    if df_results_list:\n",
    "        df_results = pd.concat(df_results_list, ignore_index=True)\n",
    "        df_results[\"length_of_recording\"] = recording_lengths\n",
    "        print(f\"Generated metrics for {len(df_results)} trajectories\")\n",
    "        \n",
    "        # Step 3: Load and merge with metadata\n",
    "        print(\"\\n== STEP 3: Merging with metadata ==\")\n",
    "        metadata_path = os.path.join(ANALYSIS_FOLDER, METADATA_FILE)\n",
    "        \n",
    "        if os.path.exists(metadata_path):\n",
    "            try:\n",
    "                # Detect delimiter\n",
    "                with open(metadata_path, 'r') as f:\n",
    "                    first_line = f.readline().strip()\n",
    "                    delimiter = ';' if ';' in first_line else ','\n",
    "                \n",
    "                df_metadata = pd.read_csv(metadata_path, delimiter=delimiter)\n",
    "                \n",
    "                # Ensure ID columns are string type for proper joining\n",
    "                df_metadata['ID'] = df_metadata['ID'].astype(str)\n",
    "                df_results['ID'] = df_results['ID'].astype(str)\n",
    "                \n",
    "                # Merge the results with metadata\n",
    "                merged_df = pd.merge(df_metadata, df_results, on='ID', how='inner')\n",
    "                \n",
    "                # Report merge statistics\n",
    "                print(f\"Merged with metadata: {len(merged_df)} matched entries\")\n",
    "                unmatched_metadata = df_metadata[~df_metadata['ID'].isin(df_results['ID'])]\n",
    "                unmatched_results = df_results[~df_results['ID'].isin(df_metadata['ID'])]\n",
    "                \n",
    "                if not unmatched_metadata.empty:\n",
    "                    print(f\"Warning: {len(unmatched_metadata)} entries in metadata not found in results\")\n",
    "                \n",
    "                if not unmatched_results.empty:\n",
    "                    print(f\"Warning: {len(unmatched_results)} entries in results not found in metadata\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing metadata: {e}\")\n",
    "                merged_df = df_results\n",
    "                \n",
    "        else:\n",
    "            print(f\"Metadata file {METADATA_FILE} not found. Using results without metadata.\")\n",
    "            merged_df = df_results\n",
    "        \n",
    "        # Step 4: Convert left/right metrics to odor/control\n",
    "        print(\"\\n== STEP 4: Converting left/right metrics to odor/control ==\")\n",
    "        \n",
    "        if 'Cote_Odor' in merged_df.columns:\n",
    "            final_df = make_correspondance_df(merged_df)\n",
    "            print(\"Successfully converted metrics to odor/control format\")\n",
    "        else:\n",
    "            print(\"Warning: 'Cote_Odor' column not found. Using original metrics.\")\n",
    "            final_df = merged_df\n",
    "        \n",
    "        # Step 5: Save results\n",
    "        if True:\n",
    "            final_csv_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILE)\n",
    "            final_df.to_csv(final_csv_path, index=False, sep=';')\n",
    "            print(f\"Final results saved to {final_csv_path}\")\n",
    "        \n",
    "        # Step 6: Generate and display summary statistics\n",
    "        print(\"\\n== STEP 6: Generating summary statistics ==\")\n",
    "        \n",
    "        # Determine grouping columns\n",
    "        group_cols = []\n",
    "        if GROUP_COLUMN in final_df.columns and final_df[GROUP_COLUMN].nunique() > 1:\n",
    "            group_cols = [GROUP_COLUMN]\n",
    "            print(f\"Using '{GROUP_COLUMN}' for grouping\")\n",
    "        else:\n",
    "            # Try to find alternative grouping columns\n",
    "            for col in ['Dose', 'Treatment', 'Hive', 'Cov','Genotype','Condition']:\n",
    "                if col in final_df.columns and final_df[col].nunique() > 1:\n",
    "                    group_cols = [col]\n",
    "                    print(f\"Using '{col}' for grouping\")\n",
    "                    break\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        summary_stats = generate_summary_statistics(final_df, group_columns=group_cols)\n",
    "        \n",
    "        if summary_stats is not None:\n",
    "            # Display summary\n",
    "            print(\"\\nSummary Statistics:\")\n",
    "            print(\"=\" * 80)\n",
    "            # Display only the most important columns\n",
    "            display_cols = group_cols + ['Count'] if group_cols else ['Group', 'Count']\n",
    "            key_metrics = ['prop_odor', 'prop_bout_odor', 'prop_proportion_odor',\n",
    "            'average_velocity_in_branch','overall_average_velocity']\n",
    "            \n",
    "            for metric in key_metrics:\n",
    "                mean_col = f\"{metric}_mean\"\n",
    "                sem_col = f\"{metric}_sem\"\n",
    "                if mean_col in summary_stats.columns and sem_col in summary_stats.columns:\n",
    "                    display_cols.extend([mean_col, sem_col])\n",
    "            \n",
    "            # Check if display columns exist in the DataFrame\n",
    "            display_cols = [col for col in display_cols if col in summary_stats.columns]\n",
    "            \n",
    "            # Print the summary\n",
    "            if display_cols:\n",
    "                print(summary_stats[display_cols].to_string(index=False))\n",
    "            else:\n",
    "                print(summary_stats.to_string(index=False))\n",
    "            \n",
    "            # Save summary statistics\n",
    "            summary_path = os.path.join(OUTPUT_FOLDER, 'summary_statistics.csv')\n",
    "            summary_stats.to_csv(summary_path, index=False, sep=';')\n",
    "            print(f\"\\nSummary statistics saved to {summary_path}\")\n",
    "        \n",
    "        # Step 7: Generate visualizations\n",
    "        if GENERATE_PLOTS and len(valid_files) > 1:\n",
    "            print(\"\\n== STEP 7: Generating visualizations ==\")\n",
    "            \n",
    "            # Create a visualization dashboard with multiple plot types\n",
    "            if group_cols:\n",
    "                group_col = group_cols[0]\n",
    "                dashboard = create_comparison_dashboard(\n",
    "                    final_df, group_col=group_col, output_folder=None  # Don't save in the function\n",
    "                )\n",
    "                \n",
    "                if dashboard:\n",
    "                    print(f\"Created visualization dashboard with {len(dashboard)} plot types\")\n",
    "                    \n",
    "                    # Save the plots manually \n",
    "                    if SAVE_RESULTS:\n",
    "                        for plot_name, fig in dashboard.items():\n",
    "                            try:\n",
    "                                output_path = os.path.join(OUTPUT_FOLDER, f\"{plot_name}.png\")\n",
    "                                if hasattr(fig, 'fig'):  # For PairGrid objects\n",
    "                                    fig.savefig(output_path, bbox_inches='tight', dpi=400, format='png')\n",
    "                                else:  # For Figure objects\n",
    "                                    fig.savefig(output_path, bbox_inches='tight', dpi=400, format='png')\n",
    "                                print(f\"Saved high-quality {plot_name} plot to {output_path}\")\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error saving {plot_name} plot: {e}\")\n",
    "                                        \n",
    "                    # Show the plots\n",
    "                    for plot_name, fig in dashboard.items():\n",
    "                        try:\n",
    "                            if hasattr(fig, 'fig'):  # For PairGrid objects\n",
    "                                plt.figure(fig.fig.number)\n",
    "                            elif hasattr(fig, 'number'):  # For Figure objects\n",
    "                                plt.figure(fig.number)\n",
    "                            plt.show()\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error displaying {plot_name} plot: {e}\")\n",
    "    else:\n",
    "        print(f\"No trajectory data was successfully analyzed. Check for errors above. Path: {FOLDER_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
